{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24ecd3f3-eed2-4a9a-9b07-2dd4c5534e85",
   "metadata": {
    "id": "24ecd3f3-eed2-4a9a-9b07-2dd4c5534e85"
   },
   "source": [
    "# Mpox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfc3ad59-fdc9-4094-9083-f8ff5539cbec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dfc3ad59-fdc9-4094-9083-f8ff5539cbec",
    "outputId": "e7f1d8c6-e006-4053-b3c6-4d06962ff7a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torchvision.models as tvm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "\n",
    "import torch.optim as to\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset\n",
    "\n",
    "%run model.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0db07df5-0b5d-450b-b882-19787ec54760",
   "metadata": {
    "id": "0db07df5-0b5d-450b-b882-19787ec54760"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce6bdf19-78f5-4465-b546-c6314ccb3549",
   "metadata": {
    "id": "ce6bdf19-78f5-4465-b546-c6314ccb3549"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sD2lrQRPR_oV",
   "metadata": {
    "id": "sD2lrQRPR_oV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e9e9770-bec6-432e-aaf5-651e7674357c",
   "metadata": {
    "id": "6e9e9770-bec6-432e-aaf5-651e7674357c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "169f9c9f-df3d-4853-a46d-7a8f717d1b25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "169f9c9f-df3d-4853-a46d-7a8f717d1b25",
    "outputId": "4e77426f-a9ef-419e-a7e7-7371e91fd4f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.12\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "print(timm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b6e34ba-11f7-4dc4-89f3-60e1cde88227",
   "metadata": {
    "id": "4b6e34ba-11f7-4dc4-89f3-60e1cde88227",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54bd7adf-ca24-465f-8509-95f51cb985a3",
   "metadata": {
    "id": "54bd7adf-ca24-465f-8509-95f51cb985a3"
   },
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluates the performance of a classification model using precision, recall, and F1-score.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (list or array-like): True labels.\n",
    "    y_pred (list or array-like): Predicted labels by the model.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Precision, Recall, and F1-Score, calculated using macro averaging.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate precision score using macro averaging (treats all classes equally)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # Calculate recall score using macro averaging\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # Calculate F1-score using macro averaging\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # Return the calculated metrics as a tuple\n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "267f1e3c-672e-4832-9bc0-ec2fe0bff61e",
   "metadata": {
    "id": "267f1e3c-672e-4832-9bc0-ec2fe0bff61e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def replace_context_modules(model, Module, dilation):\n",
    "    \"\"\"\n",
    "    Replaces the context_module in specific blocks of a model's fourth stage with a custom module.\n",
    "\n",
    "    Parameters:\n",
    "    model: The model containing stages and blocks where replacements are to be made.\n",
    "    Module: Custom module to replace the existing context_module.\n",
    "    seed: Random seed for reproducibility in the custom module.\n",
    "    \"\"\"\n",
    "\n",
    "    # Access the fourth stage (index 3) of the model\n",
    "    stage = model.stages[3]\n",
    "\n",
    "    # Loop through blocks 1 to 6 (indices 1 to 6) in the fourth stage\n",
    "    for i in range(1, 7):\n",
    "        block = stage.blocks[i]  # Access the current block\n",
    "\n",
    "        # Extract the number of input channels from the original context_module\n",
    "        in_channels = block.context_module.main.qkv.conv.in_channels\n",
    "\n",
    "        # Extract the number of output channels from the original context_module\n",
    "        out_channels = block.context_module.main.proj.conv.out_channels\n",
    "\n",
    "        # Replace the existing context_module with a new custom module\n",
    "        block.context_module = nn.Sequential(\n",
    "            Module(in_channels, nn.ReLU, dilation=dilation)  # Initialize custom module with required parameters\n",
    "        )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9G6iSswPWsIG",
   "metadata": {
    "id": "9G6iSswPWsIG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "464db3fe-8de7-423f-bbfd-41e7fe6c5965",
   "metadata": {
    "id": "464db3fe-8de7-423f-bbfd-41e7fe6c5965"
   },
   "outputs": [],
   "source": [
    "\n",
    "def change_classifier(model, model_name, num_classes=4, dropout=0.5,\n",
    "                     neurons1=4096, neurons2=1024, neurons3=256, neurons4=512, n_layers=2):\n",
    "    \"\"\"\n",
    "    Change the classifier head of various vision models\n",
    "\n",
    "    Args:\n",
    "        model: The base model to modify\n",
    "        model_name: Name/type of the model to determine input features\n",
    "        num_classes: Number of output classes\n",
    "        dropout: Dropout rate\n",
    "        neurons1-4: Number of neurons in each layer\n",
    "        n_layers: Number of layers in classifier (1-4)\n",
    "    \"\"\"\n",
    "    # Define input features based on model architecture\n",
    "    input_features = {\n",
    "        'resnet101.a1_in1k': 2048,\n",
    "        'deit3_medium_patch16_224': 512,\n",
    "        'coatnet_1_rw_224.sw_in1k': 768,\n",
    "        'mobilenetv3_large_100.ra_in1k': 1280,\n",
    "        'vit_base_patch16_224' : 768,\n",
    "        'efficientvit_l1.r224_in1k': 3072\n",
    "    }\n",
    "\n",
    "    in_features = input_features.get(model_name, 3072)  # Default to 3072 if model not found\n",
    "\n",
    "    # Create the classifier based on number of layers\n",
    "    if n_layers == 1:\n",
    "        classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features, neurons1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(neurons1, num_classes),\n",
    "            nn.Sigmoid() if num_classes == 1 else nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    elif n_layers == 2:\n",
    "        classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features, neurons1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(neurons1, neurons2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(neurons2, num_classes),\n",
    "            nn.Sigmoid() if num_classes == 1 else nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    elif n_layers == 3:\n",
    "        classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features, neurons1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(neurons1, neurons2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(neurons2, neurons3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(neurons3, num_classes),\n",
    "            nn.Sigmoid() if num_classes == 1 else nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    else:  # 4 layers\n",
    "        classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features, neurons1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(neurons1, neurons2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(neurons2, neurons3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(neurons3, neurons4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(neurons4, num_classes),\n",
    "            nn.Sigmoid() if num_classes == 1 else nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    # Determine where to attach the classifier based on model type\n",
    "    if hasattr(model, 'head'):\n",
    "      if hasattr(model.head, 'classifier'):\n",
    "        model.head.classifier = classifier\n",
    "\n",
    "      elif hasattr(model.head, 'fc'):\n",
    "        model.head.fc = classifier\n",
    "      else:\n",
    "         model.head = classifier\n",
    "    elif hasattr(model, 'fc'):\n",
    "      model.fc = classifier\n",
    "    elif hasattr(model, 'classifier'):\n",
    "      model.classifier = classifier\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        raise AttributeError(\"Model structure not supported. Cannot find classifier or head attribute.\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c13559c-2e87-474d-9769-d84da558d30a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5c13559c-2e87-474d-9769-d84da558d30a",
    "outputId": "8d27af11-8e2a-4be1-91bc-db2dafde23db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79362e82-c190-43bb-a44c-548f72ed1e3f",
   "metadata": {
    "id": "79362e82-c190-43bb-a44c-548f72ed1e3f"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f611664d-24de-423c-b745-a33fe355ac2a",
   "metadata": {
    "id": "f611664d-24de-423c-b745-a33fe355ac2a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c9a511e-c700-4cd6-b74b-1e41b0abb7b9",
   "metadata": {
    "id": "5c9a511e-c700-4cd6-b74b-1e41b0abb7b9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3d68765-0e15-4956-b4d6-d96b8da4f510",
   "metadata": {
    "id": "a3d68765-0e15-4956-b4d6-d96b8da4f510"
   },
   "outputs": [],
   "source": [
    "class_labels = {\n",
    "    'monkey_pox' : [ 1 , 0 , 0 , 0],  # Label encoding for 'monkey_pox' class\n",
    "    'normal' : [ 0 , 1 , 0 , 0],      # Label encoding for 'normal' class\n",
    "    'chicken_pox' : [ 0 , 0 , 1 , 0], # Label encoding for 'chicken_pox' class\n",
    "    'acne' : [ 0 , 0 , 0 , 1],        # Label encoding for 'acne' class\n",
    "}\n",
    "\n",
    "def acc_eval(outputs, labels, classwise=False):\n",
    "    \"\"\"\n",
    "    Evaluate accuracy of model predictions.\n",
    "\n",
    "    Args:\n",
    "        outputs (torch.Tensor): Model predictions (one-hot encoded).\n",
    "        labels (torch.Tensor): Ground truth labels (one-hot encoded).\n",
    "        classwise (bool): If True, calculate and return class-wise accuracy.\n",
    "\n",
    "    Returns:\n",
    "        int: Total correct predictions if classwise=False.\n",
    "        tuple: Total correct predictions and class-wise counts if classwise=True.\n",
    "    \"\"\"\n",
    "    right = 0  # Counter for correct predictions\n",
    "    class_rights = {class_name: 0 for class_name in class_labels.keys()}  # Initialize class-wise correct counters\n",
    "\n",
    "    for j in range(outputs.shape[0]):  # Loop over all predictions in the batch\n",
    "        max_value = torch.max(outputs[j])  # Get the maximum value in the current prediction\n",
    "        outputs[j] = (outputs[j] == max_value).float()  # Convert to one-hot representation by retaining the max value index\n",
    "        if torch.all(outputs[j].eq(labels[j])):  # Check if the prediction matches the ground truth\n",
    "            right += 1  # Increment total correct counter\n",
    "            if classwise:  # If classwise evaluation is required\n",
    "                label_list = labels[j].detach().cpu().tolist()  # Convert label tensor to list for comparison\n",
    "                for class_name, class_label in class_labels.items():  # Loop through each class label\n",
    "                    if label_list == class_label:  # Check if the ground truth matches the current class label\n",
    "                        class_rights[class_name] += 1  # Increment correct counter for the class\n",
    "                        break  # Exit the loop once the class is identified\n",
    "    if not classwise:  # Return total correct predictions if classwise=False\n",
    "        return right\n",
    "    else:  # Return total correct predictions and class-wise correct counts if classwise=True\n",
    "        return (right, *class_rights.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84713b2a-975b-4bbc-b7a8-ce2390295a7a",
   "metadata": {
    "id": "84713b2a-975b-4bbc-b7a8-ce2390295a7a"
   },
   "outputs": [],
   "source": [
    "def cal_total(labels):\n",
    "    \"\"\"\n",
    "    Calculate the total count of labels for each class.\n",
    "\n",
    "    Args:\n",
    "        labels (torch.Tensor): Ground truth labels (one-hot encoded).\n",
    "\n",
    "    Returns:\n",
    "        tuple: Total counts for each class, in the order of class_labels keys.\n",
    "    \"\"\"\n",
    "    # Initialize a dictionary to store the total count for each class\n",
    "    class_totals = {class_name: 0 for class_name in class_labels.keys()}\n",
    "\n",
    "    for j in range(labels.shape[0]):  # Loop over all labels in the batch\n",
    "        label_list = labels[j].detach().cpu().tolist()  # Convert label tensor to a list\n",
    "        for class_name, class_label in class_labels.items():  # Iterate through all class labels\n",
    "            if label_list == class_label:  # Check if the label matches the current class\n",
    "                class_totals[class_name] += 1  # Increment the count for the matched class\n",
    "                break  # Exit the loop once the class is identified\n",
    "\n",
    "    # Return the total counts for each class as a tuple\n",
    "    return tuple(class_totals.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51f6178f-64cd-4f99-bbd3-e90c2303332c",
   "metadata": {
    "id": "51f6178f-64cd-4f99-bbd3-e90c2303332c"
   },
   "outputs": [],
   "source": [
    "def norm(X_train, X_val, X_test):\n",
    "    \"\"\"\n",
    "    Normalize training, validation, and test datasets using training set statistics.\n",
    "    \"\"\"\n",
    "    meanx = X_train.mean()  # Calculate training set mean\n",
    "    stdx = X_train.std()    # Calculate training set std\n",
    "\n",
    "    # Normalize datasets using training set mean and std\n",
    "    X_train = (X_train - meanx) / stdx\n",
    "    X_valid = (X_val - meanx) / stdx\n",
    "    X_test = (X_test - meanx) / stdx\n",
    "\n",
    "    return X_train, X_valid, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f7dd141-6463-40e0-ad01-8430095a29bf",
   "metadata": {
    "id": "3f7dd141-6463-40e0-ad01-8430095a29bf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0542860-41f2-45b3-9c68-425647660d4f",
   "metadata": {
    "id": "e0542860-41f2-45b3-9c68-425647660d4f",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7d58417-8fd8-40e4-914b-49ee9f46a3c1",
   "metadata": {
    "id": "b7d58417-8fd8-40e4-914b-49ee9f46a3c1"
   },
   "outputs": [],
   "source": [
    "def test(model, training_loader, model_num):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test dataset and compute accuracy, precision, recall, F1 score,\n",
    "    and per-class accuracies.\n",
    "    \"\"\"\n",
    "    right_total = 0  # Total correct predictions\n",
    "    total = 0  # Total number of samples\n",
    "    out = []  # List to store predicted labels\n",
    "    lab = []  # List to store true labels\n",
    "    class_totals = {class_name: 0 for class_name in class_labels.keys()}  # Per-class sample counts\n",
    "    class_rights = {class_name: 0 for class_name in class_labels.keys()}  # Per-class correct predictions\n",
    "\n",
    "    for i, data in enumerate(tqdm(training_loader)):  # Iterate over the training data\n",
    "        inputs, labels = data  # Get inputs and labels\n",
    "        total += inputs.shape[0]  # Update total samples\n",
    "\n",
    "        outputs = model(inputs)  # Get model predictions\n",
    "\n",
    "        # Get per-class totals and correct predictions\n",
    "        class_totals_batch = cal_total(labels)\n",
    "        right, *class_rights_batch = acc_eval(outputs, labels, classwise=True)\n",
    "\n",
    "        right_total += right  # Update total correct predictions\n",
    "        for i, class_name in enumerate(class_labels.keys()):  # Update per-class totals and rights\n",
    "            class_totals[class_name] += class_totals_batch[i]\n",
    "            class_rights[class_name] += class_rights_batch[i]\n",
    "\n",
    "        # Convert outputs and labels to numpy arrays for evaluation\n",
    "        outputs = np.array(outputs.detach().cpu(), dtype='object')\n",
    "        labels = np.array(labels.detach().cpu(), dtype='object')\n",
    "\n",
    "        out.extend(np.argmax(outputs, axis=1))  # Store predicted labels\n",
    "        lab.extend(np.argmax(labels, axis=1))  # Store true labels\n",
    "\n",
    "    accuracy = right_total / total  # Calculate overall accuracy\n",
    "    class_accuracies = {class_name: class_rights[class_name] / class_totals[class_name]\n",
    "                        if class_totals[class_name] > 0 else 0\n",
    "                        for class_name in class_labels.keys()}  # Calculate per-class accuracies\n",
    "\n",
    "    precision, recall, f1 = evaluate(out, lab)  # Evaluate precision, recall, and F1 score\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)  # Print overall accuracy\n",
    "    print(\"Total Right:\", right_total)  # Print total correct predictions\n",
    "    for class_name, class_accuracy in class_accuracies.items():  # Print per-class accuracy\n",
    "        print(f\"{class_name} Accuracy: {class_accuracy}\")\n",
    "\n",
    "    return (accuracy, precision, recall, f1, *class_accuracies.values())  # Return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edc659e3-125f-4b3f-961c-5175759be21b",
   "metadata": {
    "id": "edc659e3-125f-4b3f-961c-5175759be21b"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, epoch_index, model_num, training_loader, loss_fn, loss_fn1, w, optimizer, loss_dict_train):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch, computing losses and accuracies, and updating model weights.\n",
    "\n",
    "    Args:\n",
    "        model: The neural network model to train.\n",
    "        epoch_index: The index of the current epoch.\n",
    "        model_num: Identifier for the model (used for loss tracking).\n",
    "        training_loader: DataLoader object for training dataset.\n",
    "        loss_fn: Primary loss function used for training.\n",
    "        loss_fn1: Secondary loss function used for training (combined with loss_fn).\n",
    "        w: Weighting factor for combining loss_fn and loss_fn1.\n",
    "        optimizer: Optimizer to update model parameters.\n",
    "        loss_dict_train: Dictionary to track losses for the training process.\n",
    "\n",
    "    Returns:\n",
    "        last_loss: The average loss for the last batch in the epoch.\n",
    "        overall_accuracy: The overall accuracy of the model on the training dataset.\n",
    "        right_total: Total number of correct predictions in the epoch.\n",
    "        class_accuracies: Per-class accuracy for each class in the dataset.\n",
    "    \"\"\"\n",
    "    running_loss = 0.  # To track cumulative loss for the current epoch\n",
    "    last_loss = 0.  # To store the average loss for the last batch\n",
    "    right_total = 0  # Total correct predictions\n",
    "    total = 0  # Total samples processed\n",
    "\n",
    "    class_totals = {class_name: 0 for class_name in class_labels.keys()}  # Store count of each class in the batch\n",
    "    class_rights = {class_name: 0 for class_name in class_labels.keys()}  # Store correct predictions for each class\n",
    "\n",
    "    # Iterate through batches in the training set\n",
    "    for i, data in enumerate(tqdm(training_loader)):\n",
    "        inputs, labels = data  # Get input images and corresponding labels\n",
    "        optimizer.zero_grad()  # Reset gradients to zero before backpropagation\n",
    "        outputs = model(inputs)  # Get model predictions\n",
    "\n",
    "        total += inputs.shape[0]  # Update the total number of samples processed\n",
    "        # Compute the loss as a weighted combination of the two loss functions\n",
    "        loss = (1-w) * loss_fn(outputs, labels) + w * loss_fn1(outputs, labels)\n",
    "        loss.backward()  # Backpropagate the loss\n",
    "        optimizer.step()  # Update the model weights using the optimizer\n",
    "\n",
    "        # Get per-class totals and correct predictions\n",
    "        class_totals_batch = cal_total(labels)\n",
    "        right, *class_rights_batch = acc_eval(outputs, labels, classwise=True)\n",
    "\n",
    "        right_total += right  # Update the total correct predictions\n",
    "        # Update per-class totals and correct predictions\n",
    "        for j, class_name in enumerate(class_labels.keys()):\n",
    "            class_totals[class_name] += class_totals_batch[j]\n",
    "            class_rights[class_name] += class_rights_batch[j]\n",
    "\n",
    "        running_loss += loss.item()  # Add current batch loss to running total\n",
    "        # Print the average loss for every 10 batches\n",
    "        if i % 10 == 9:\n",
    "            last_loss = running_loss / 10  # Calculate the average loss for the last 10 batches\n",
    "            print(f'  batch {i + 1} loss: {last_loss}')\n",
    "            running_loss = 0.  # Reset running loss for the next set of batches\n",
    "\n",
    "    # Calculate per-class accuracies\n",
    "    print(\"Class totals:\", class_totals)\n",
    "    class_accuracies = {}\n",
    "    for class_name in class_labels.keys():\n",
    "        if class_totals[class_name] == 0:\n",
    "            class_accuracies[class_name] = None  # No data for this class\n",
    "        else:\n",
    "            class_accuracies[class_name] = class_rights[class_name] / class_totals[class_name]  # Calculate class accuracy\n",
    "\n",
    "    # Calculate overall accuracy\n",
    "    overall_accuracy = right_total / total if total > 0 else None\n",
    "\n",
    "    # Return the last loss, overall accuracy, total correct predictions, and class-wise accuracies\n",
    "    return (last_loss, overall_accuracy, right_total,\n",
    "            *[class_accuracies[class_name] for class_name in class_labels.keys()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "vKPBSw9V0zcO",
   "metadata": {
    "id": "vKPBSw9V0zcO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class CAGA(nn.Module):\n",
    "    \"\"\"\n",
    "      Attributes:\n",
    "          heads: Number of attention heads in the multi-head attention mechanism.\n",
    "          dim: Dimensionality of Q, K, V.\n",
    "          scale: Scaling factor for the attention computation.\n",
    "          head_dim: The number of channels per attention head.\n",
    "          dilation: List of dilation values for dilated convolutions.\n",
    "          total_layer: Total number of layers used in the module.\n",
    "          get_begin: Initial convolutional layer for feature extraction.\n",
    "          get_qkv: List of convolutional layers to compute queries, keys, and values.\n",
    "          convert_to_headdim: Layer to combine and reshape the outputs of all dilated convolutions.\n",
    "          mix: Convolutional layers to refine the features.\n",
    "          proj: Final projection layer to map the concatenated features to the input shape.\n",
    "          norm: Batch normalization layer to normalize the output.\n",
    "      \"\"\"\n",
    "    def __init__(self,\n",
    "            in_channels,\n",
    "            activation,\n",
    "            heads = 3,\n",
    "            dim = 8,\n",
    "            expand_ratio = 4,\n",
    "            head_dim = 16,\n",
    "            dilation = (1,2),\n",
    "            random_seed = 82\n",
    "            ):\n",
    "\n",
    "        # Set global random seeds for reproducibility\n",
    "        self._set_global_seeds(random_seed)\n",
    "\n",
    "        super(CAGA, self).__init__()\n",
    "        self.heads = heads\n",
    "        self.dim = dim\n",
    "        scale = dim\n",
    "        self.scale = dim ** -0.5\n",
    "        self.head_dim = head_dim\n",
    "        self.dilation = dilation\n",
    "\n",
    "        self.total_layer = 4\n",
    "\n",
    "        # Reproducible layer initialization\n",
    "        self.get_begin = self._init_depthwise_separable_conv(\n",
    "            DepthWiseSeperableConvLayer(in_channels, self.heads * self.head_dim)\n",
    "        )\n",
    "\n",
    "        self.get_qkv = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                self._init_conv(nn.Conv2d(\n",
    "                    self.head_dim,\n",
    "                    self.head_dim,\n",
    "                    3,\n",
    "                    groups=self.head_dim,\n",
    "                    dilation=di\n",
    "                )),\n",
    "                self._init_conv(nn.Conv2d(self.head_dim, 3 * self.dim, 1, groups=1))\n",
    "            )\n",
    "            for di in dilation\n",
    "        ])\n",
    "\n",
    "        self.convert_to_headdim = self._init_conv(\n",
    "            nn.Conv2d(len(dilation) * self.dim, self.head_dim, 1)\n",
    "        )\n",
    "\n",
    "        self.mix = nn.Sequential(\n",
    "            self._init_conv(nn.Conv2d(\n",
    "                self.dim,\n",
    "                self.dim * 3,\n",
    "                1\n",
    "            )),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.proj = self._init_conv(\n",
    "            nn.Conv2d(self.heads * self.dim * len(self.dilation), in_channels, 1)\n",
    "        )\n",
    "\n",
    "        # Deterministic BatchNorm\n",
    "        self.norm = nn.BatchNorm2d(num_features=in_channels, affine=True)\n",
    "        nn.init.constant_(self.norm.weight, 1)\n",
    "        nn.init.constant_(self.norm.bias, 0)\n",
    "\n",
    "    def _set_global_seeds(self, seed):\n",
    "        \"\"\"Set seeds for reproducibility across libraries.\"\"\"\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "    def _init_conv(self, conv_layer):\n",
    "        \"\"\"Initialize convolutional layer weights deterministically.\"\"\"\n",
    "        nn.init.xavier_uniform_(conv_layer.weight)\n",
    "        if conv_layer.bias is not None:\n",
    "            nn.init.constant_(conv_layer.bias, 0)\n",
    "        return conv_layer\n",
    "\n",
    "    def _init_depthwise_separable_conv(self, conv_layer):\n",
    "        \"\"\"Initialize depthwise separable convolution layers.\"\"\"\n",
    "        # Assuming DepthWiseSeperableConvLayer has similar structure to standard conv\n",
    "        for m in conv_layer.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "        return conv_layer\n",
    "        # self.norm = nn.LayerNorm([8, 256, 14, 14])\n",
    "\n",
    "\n",
    "\n",
    "    def attention(self,q,k,v , shape):\n",
    "\n",
    "        B, C, H, W = shape\n",
    "\n",
    "\n",
    "\n",
    "        q, k, v = q.float(), k.float(), v.float()\n",
    "\n",
    "\n",
    "        q = q * self.scale\n",
    "        att_map = q.transpose(-2, -1) @ k\n",
    "\n",
    "\n",
    "        att_map = att_map.softmax(dim=-1)\n",
    "\n",
    "\n",
    "        out = v @ att_map.transpose(-2, -1)\n",
    "\n",
    "        out = out.view(B , -1 , H , W)\n",
    "\n",
    "\n",
    "\n",
    "        return out\n",
    "\n",
    "    def forward(self,x):\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "\n",
    "\n",
    "            # print(op)\n",
    "\n",
    "        x_copy = x\n",
    "\n",
    "        all_heads  = self.get_begin(x)\n",
    "\n",
    "        multi_layer = all_heads.split([self.head_dim]*self.heads , dim=1)\n",
    "\n",
    "        all_heads_after_op = [[]]*self.heads\n",
    "\n",
    "\n",
    "\n",
    "        for j in range(self.heads):\n",
    "\n",
    "            for op in self.get_qkv:\n",
    "\n",
    "                all_heads_after_op[j].append(op(multi_layer[j]))\n",
    "\n",
    "\n",
    "        all_final = []\n",
    "\n",
    "\n",
    "        for i in range(self.heads):\n",
    "            out_all = []\n",
    "            for j in range(len(self.dilation ) ):\n",
    "\n",
    "\n",
    "\n",
    "                q , k , v = all_heads_after_op[i][j].split([self.dim, self.dim, self.dim], dim=1)\n",
    "                shape = q.shape\n",
    "                q, k, v = q.flatten(2), k.flatten(2), v.flatten(2)\n",
    "                out = self.attention(q , k , v , shape)\n",
    "\n",
    "\n",
    "\n",
    "                # print(out.shape)\n",
    "                shape_ahead = all_heads_after_op[i][j+1].shape[3]\n",
    "\n",
    "                temp = torchvision.transforms.functional.resize(out , (shape_ahead,shape_ahead))\n",
    "\n",
    "                out = F.interpolate(out, size=( H , W ), mode='bilinear')\n",
    "                out = out.view(B, self.dim, H, W)\n",
    "\n",
    "\n",
    "                if j+1 != len(self.dilation ):\n",
    "\n",
    "                    temp = self.mix(temp).clone()\n",
    "                    all_heads_after_op[i][j+1] = all_heads_after_op[i][j+1] + temp\n",
    "\n",
    "                out_all.append(out)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            out_all_one = torch.cat(out_all, dim=1)\n",
    "            all_final.append(out_all_one)\n",
    "            if i+1 != self.heads:\n",
    "                all_heads_after_op[i+1] += self.convert_to_headdim(out_all_one)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      # we need to billinear intterpolate before append\n",
    "        all_concat = torch.cat(all_final, dim=1)\n",
    "\n",
    "\n",
    "        x_final = self.proj(all_concat) + x_copy # try oncat later\n",
    "\n",
    "        return self.norm (x_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8vV9ctM1ovJf",
   "metadata": {
    "id": "8vV9ctM1ovJf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class CAGA_nocascading_in_CAA(nn.Module):\n",
    "    \"\"\"\n",
    "    This for ablation study\n",
    "      Attributes:\n",
    "          heads: Number of attention heads in the multi-head attention mechanism.\n",
    "          dim: Dimensionality of Q, K, V.\n",
    "          scale: Scaling factor for the attention computation.\n",
    "          head_dim: The number of channels per attention head.\n",
    "          dilation: List of dilation values for dilated convolutions.\n",
    "          total_layer: Total number of layers used in the module.\n",
    "          get_begin: Initial convolutional layer for feature extraction.\n",
    "          get_qkv: List of convolutional layers to compute queries, keys, and values.\n",
    "          convert_to_headdim: Layer to combine and reshape the outputs of all dilated convolutions.\n",
    "          mix: Convolutional layers to refine the features.\n",
    "          proj: Final projection layer to map the concatenated features to the input shape.\n",
    "          norm: Batch normalization layer to normalize the output.\n",
    "      \"\"\"\n",
    "    def __init__(self,\n",
    "            in_channels,\n",
    "            activation,\n",
    "            heads = 3,\n",
    "            dim = 8,\n",
    "            expand_ratio = 4,\n",
    "            head_dim = 16,\n",
    "            dilation = (1,2),\n",
    "            random_seed = 82\n",
    "            ):\n",
    "\n",
    "        # Set global random seeds for reproducibility\n",
    "        self._set_global_seeds(random_seed)\n",
    "\n",
    "        super(CAGA_nocascading_in_CAA, self).__init__()\n",
    "        self.heads = heads\n",
    "        self.dim = dim\n",
    "        scale = dim\n",
    "        self.scale = dim ** -0.5\n",
    "        self.head_dim = head_dim\n",
    "        self.dilation = dilation\n",
    "\n",
    "        self.total_layer = 4\n",
    "\n",
    "        # Reproducible layer initialization\n",
    "        self.get_begin = self._init_depthwise_separable_conv(\n",
    "            DepthWiseSeperableConvLayer(in_channels, self.heads * self.head_dim)\n",
    "        )\n",
    "\n",
    "        self.get_qkv = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                self._init_conv(nn.Conv2d(\n",
    "                    self.head_dim,\n",
    "                    self.head_dim,\n",
    "                    3,\n",
    "                    groups=self.head_dim,\n",
    "                    dilation=di\n",
    "                )),\n",
    "                self._init_conv(nn.Conv2d(self.head_dim, 3 * self.dim, 1, groups=1))\n",
    "            )\n",
    "            for di in dilation\n",
    "        ])\n",
    "\n",
    "        self.convert_to_headdim = self._init_conv(\n",
    "            nn.Conv2d(len(dilation) * self.dim, self.head_dim, 1)\n",
    "        )\n",
    "\n",
    "        self.mix = nn.Sequential(\n",
    "            self._init_conv(nn.Conv2d(\n",
    "                self.dim,\n",
    "                self.dim * 3,\n",
    "                1\n",
    "            )),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.proj = self._init_conv(\n",
    "            nn.Conv2d(self.heads * self.dim * len(self.dilation), in_channels, 1)\n",
    "        )\n",
    "\n",
    "        # Deterministic BatchNorm\n",
    "        self.norm = nn.BatchNorm2d(num_features=in_channels, affine=True)\n",
    "        nn.init.constant_(self.norm.weight, 1)\n",
    "        nn.init.constant_(self.norm.bias, 0)\n",
    "\n",
    "    def _set_global_seeds(self, seed):\n",
    "        \"\"\"Set seeds for reproducibility across libraries.\"\"\"\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "    def _init_conv(self, conv_layer):\n",
    "        \"\"\"Initialize convolutional layer weights deterministically.\"\"\"\n",
    "        nn.init.xavier_uniform_(conv_layer.weight)\n",
    "        if conv_layer.bias is not None:\n",
    "            nn.init.constant_(conv_layer.bias, 0)\n",
    "        return conv_layer\n",
    "\n",
    "    def _init_depthwise_separable_conv(self, conv_layer):\n",
    "        \"\"\"Initialize depthwise separable convolution layers.\"\"\"\n",
    "        # Assuming DepthWiseSeperableConvLayer has similar structure to standard conv\n",
    "        for m in conv_layer.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "        return conv_layer\n",
    "        # self.norm = nn.LayerNorm([8, 256, 14, 14])\n",
    "\n",
    "\n",
    "\n",
    "    def attention(self,q,k,v , shape):\n",
    "\n",
    "        B, C, H, W = shape\n",
    "\n",
    "\n",
    "\n",
    "        q, k, v = q.float(), k.float(), v.float()\n",
    "\n",
    "\n",
    "        q = q * self.scale\n",
    "        att_map = q.transpose(-2, -1) @ k\n",
    "\n",
    "\n",
    "        att_map = att_map.softmax(dim=-1)\n",
    "\n",
    "\n",
    "        out = v @ att_map.transpose(-2, -1)\n",
    "\n",
    "        out = out.view(B , -1 , H , W)\n",
    "\n",
    "\n",
    "\n",
    "        return out\n",
    "\n",
    "    def forward(self,x):\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "\n",
    "\n",
    "            # print(op)\n",
    "\n",
    "        x_copy = x\n",
    "\n",
    "        all_heads  = self.get_begin(x)\n",
    "\n",
    "        multi_layer = all_heads.split([self.head_dim]*self.heads , dim=1)\n",
    "\n",
    "        all_heads_after_op = [[]]*self.heads\n",
    "\n",
    "\n",
    "\n",
    "        for j in range(self.heads):\n",
    "\n",
    "            for op in self.get_qkv:\n",
    "\n",
    "                all_heads_after_op[j].append(op(multi_layer[j]))\n",
    "\n",
    "\n",
    "        all_final = []\n",
    "\n",
    "\n",
    "        for i in range(self.heads):\n",
    "            out_all = []\n",
    "            for j in range(len(self.dilation ) ):\n",
    "\n",
    "\n",
    "\n",
    "                q , k , v = all_heads_after_op[i][j].split([self.dim, self.dim, self.dim], dim=1)\n",
    "                shape = q.shape\n",
    "                q, k, v = q.flatten(2), k.flatten(2), v.flatten(2)\n",
    "                out = self.attention(q , k , v , shape)\n",
    "\n",
    "\n",
    "\n",
    "                # print(out.shape)\n",
    "                shape_ahead = all_heads_after_op[i][j+1].shape[3]\n",
    "\n",
    "                temp = torchvision.transforms.functional.resize(out , (shape_ahead,shape_ahead))\n",
    "\n",
    "                out = F.interpolate(out, size=( H , W ), mode='bilinear')\n",
    "                out = out.view(B, self.dim, H, W)\n",
    "\n",
    "\n",
    "               # if j+1 != len(self.dilation ):\n",
    "\n",
    "                #    temp = self.mix(temp).clone()\n",
    "                 #   all_heads_after_op[i][j+1] = all_heads_after_op[i][j+1] + temp\n",
    "\n",
    "                out_all.append(out)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            out_all_one = torch.cat(out_all, dim=1)\n",
    "            all_final.append(out_all_one)\n",
    "            if i+1 != self.heads:\n",
    "                all_heads_after_op[i+1] += self.convert_to_headdim(out_all_one)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      # we need to billinear intterpolate before append\n",
    "        all_concat = torch.cat(all_final, dim=1)\n",
    "\n",
    "\n",
    "        x_final = self.proj(all_concat) + x_copy # try oncat later\n",
    "\n",
    "        return self.norm (x_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "y8neIxHjak06",
   "metadata": {
    "id": "y8neIxHjak06"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fef97e6c-20f5-47bf-8a91-6ec50aea4c48",
   "metadata": {
    "id": "fef97e6c-20f5-47bf-8a91-6ec50aea4c48"
   },
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        # Initialize parameters for early stopping\n",
    "        # patience: number of consecutive epochs to wait before stopping if no improvement\n",
    "        # min_delta: minimum change in validation accuracy to qualify as an improvement\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0  # Counter to track consecutive epochs without improvement\n",
    "        self.max_validation_acc = float('-inf')  # Highest validation accuracy observed so far\n",
    "        self.val_acc_1 = 0  # Flag to track if a perfect accuracy threshold is reached\n",
    "        self.perfect_val_count = 6  # Number of epochs to wait after perfect validation accuracy\n",
    "\n",
    "    def early_stop(self, validation_acc):\n",
    "        # Method to determine if early stopping criteria are met\n",
    "\n",
    "        # If validation accuracy exceeds 0.97 for the first time\n",
    "        if validation_acc > 0.97 and self.val_acc_1 == 0:\n",
    "            self.counter = 0  # Reset counter\n",
    "            self.val_acc_1 = 1  # Mark the perfect validation flag\n",
    "\n",
    "        # If perfect validation accuracy is already flagged\n",
    "        elif self.val_acc_1 > 0.97:\n",
    "            self.counter += 1  # Increment counter\n",
    "            # Stop if the perfect validation condition persists for the defined count\n",
    "            if self.counter >= self.perfect_val_count:\n",
    "                return (True, self.counter)\n",
    "\n",
    "        else:\n",
    "            # Update the maximum validation accuracy if the current is better\n",
    "            if validation_acc > self.max_validation_acc:\n",
    "                self.max_validation_acc = validation_acc\n",
    "                self.counter = 0  # Reset counter\n",
    "            # If validation accuracy drops below the threshold (with min_delta tolerance)\n",
    "            elif validation_acc <= (self.max_validation_acc - self.min_delta):\n",
    "                print(\"max_acc\", self.max_validation_acc)  # Debug print statement\n",
    "                self.counter += 1  # Increment counter\n",
    "                # Stop if the patience limit is reached\n",
    "                if self.counter >= self.patience:\n",
    "                    return (True, self.counter)\n",
    "\n",
    "        # Return False to indicate training can continue and the current counter value\n",
    "        return (False, self.counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1c63418-0d43-496a-90a8-4212a0b17260",
   "metadata": {
    "id": "b1c63418-0d43-496a-90a8-4212a0b17260"
   },
   "outputs": [],
   "source": [
    "class FocalCELoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean', num_classes=4, device=None):\n",
    "        \"\"\"\n",
    "        Focal Cross Entropy Loss\n",
    "\n",
    "        Args:\n",
    "            alpha (torch.Tensor, optional): Weight for each class. Must be of size C.\n",
    "            gamma (float): Focusing parameter to reduce the relative loss for well-classified examples.\n",
    "            reduction (str): Reduction method for the final loss ('none', 'mean', or 'sum').\n",
    "            num_classes (int): Number of classes in the classification task.\n",
    "            device (torch.device): Device on which to place the class weights and other tensors.\n",
    "        \"\"\"\n",
    "        super(FocalCELoss, self).__init__()\n",
    "        self.gamma = gamma  # Focusing parameter for down-weighting well-classified examples\n",
    "        self.reduction = reduction  # Reduction method for the loss\n",
    "        self.device = device if device is not None else torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Handle class weights (alpha) if provided\n",
    "        if alpha is not None:\n",
    "            if isinstance(alpha, (list, tuple)):\n",
    "                self.alpha = torch.tensor(alpha)  # Convert list/tuple to tensor\n",
    "            else:\n",
    "                self.alpha = alpha  # Use alpha directly if it is already a tensor\n",
    "            assert len(self.alpha) == num_classes, \"Alpha size must match the number of classes\"\n",
    "            # Move alpha tensor to the specified device\n",
    "            self.alpha = self.alpha.to(self.device)\n",
    "        else:\n",
    "            self.alpha = None  # If alpha is not provided, no weighting is applied\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Forward pass to compute the Focal Cross Entropy Loss.\n",
    "\n",
    "        Args:\n",
    "            inputs: Tensor of shape (N, C), where N is the batch size and C is the number of classes.\n",
    "            targets: Tensor of shape (N,), containing class indices in the range [0, C-1].\n",
    "        \"\"\"\n",
    "        # Ensure inputs and targets are on the same device as the class weights (alpha)\n",
    "        inputs = inputs.to(self.device)\n",
    "        targets = targets.to(self.device)\n",
    "\n",
    "        # Compute the standard cross-entropy loss without reduction\n",
    "        ce_loss = F.cross_entropy(inputs, targets, weight=self.alpha, reduction='none')\n",
    "\n",
    "        # Compute the probability of the predicted class (pt)\n",
    "        pt = torch.exp(-ce_loss)  # pt is the probability of the true class\n",
    "\n",
    "        # Compute the Focal Loss by scaling the cross-entropy loss with the modulating factor\n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "\n",
    "        # Apply the specified reduction method\n",
    "        if self.reduction == 'mean':\n",
    "            return torch.mean(focal_loss)  # Return the mean loss\n",
    "        elif self.reduction == 'sum':\n",
    "            return torch.sum(focal_loss)  # Return the sum of the loss\n",
    "        else:  # 'none'\n",
    "            return focal_loss  # Return the loss for each sample without reduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7d3394e-da17-4eb6-96ac-89e3593e7f6d",
   "metadata": {
    "id": "b7d3394e-da17-4eb6-96ac-89e3593e7f6d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "Zb1bpnwQa2eu",
   "metadata": {
    "id": "Zb1bpnwQa2eu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class CAA(nn.Module):\n",
    "    \"\"\"\n",
    "    Cascaded Atrous Attention (CAA) Module for Ablation Study.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "            in_channels,\n",
    "            activation,\n",
    "            heads=3,  # Number of attention heads, set to 3 for experimentation\n",
    "            dim=8,  # Dimensionality of query, key, and value\n",
    "            expand_ratio=4,\n",
    "            head_dim=16,  # Dimensionality of each attention head\n",
    "            dilation = (1, 2, None),\n",
    "            random_seed=82  # Seed for reproducibility\n",
    "            ):\n",
    "        \"\"\"\n",
    "        Initialize the CAA module.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels.\n",
    "            activation (nn.Module): Activation function.\n",
    "            heads (int): Number of attention heads.\n",
    "            dim (int): Dimensionality of query, key, and value vectors.\n",
    "            expand_ratio (int): Ratio for expansion layers (not used here).\n",
    "            head_dim (int): Dimensionality of each head.\n",
    "            random_seed (int): Seed for reproducibility across runs.\n",
    "        \"\"\"\n",
    "\n",
    "        # Set global random seeds for reproducibility\n",
    "        self._set_global_seeds(random_seed)\n",
    "\n",
    "        super(CAA, self).__init__()\n",
    "        self.heads = heads\n",
    "        self.dim = dim\n",
    "        self.scale = dim ** -0.5\n",
    "        self.head_dim = head_dim\n",
    "\n",
    "        # Dilation rates for each head (first two heads use dilation, last does not)\n",
    "        self.dilations = dilation\n",
    "        self.total_layer = 3  # Total number of layers\n",
    "\n",
    "        # Initial depthwise separable convolution\n",
    "        self.get_begin = self._init_depthwise_separable_conv(\n",
    "            DepthWiseSeperableConvLayer(in_channels, self.heads * self.head_dim)\n",
    "        )\n",
    "\n",
    "        # Query, Key, Value layers with selective dilation\n",
    "        self.get_qkv = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                self._init_conv(nn.Conv2d(\n",
    "                    self.head_dim,\n",
    "                    self.head_dim,\n",
    "                    3,\n",
    "                    groups=self.head_dim,\n",
    "                    dilation=self.dilations[i] if self.dilations[i] is not None else 1\n",
    "                )),\n",
    "                self._init_conv(nn.Conv2d(self.head_dim, 3 * self.dim, 1, groups=1))\n",
    "            )\n",
    "            for i in range(self.heads)\n",
    "        ])\n",
    "\n",
    "        # Projections between heads\n",
    "        self.head_projections = nn.ModuleList([\n",
    "            self._init_conv(nn.Conv2d(self.dim, self.head_dim, 1))\n",
    "            for _ in range(self.heads - 1)\n",
    "        ])\n",
    "\n",
    "        # Final projection layer\n",
    "        self.proj = self._init_conv(\n",
    "            nn.Conv2d(self.heads * self.dim, in_channels, 1)\n",
    "        )\n",
    "\n",
    "        # Batch normalization for stability\n",
    "        self.norm = nn.BatchNorm2d(num_features=in_channels, affine=True)\n",
    "        nn.init.constant_(self.norm.weight, 1)\n",
    "        nn.init.constant_(self.norm.bias, 0)\n",
    "\n",
    "    def _set_global_seeds(self, seed):\n",
    "        \"\"\"Set seeds for reproducibility across libraries.\"\"\"\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "    def _init_conv(self, conv_layer):\n",
    "        \"\"\"Initialize convolutional layer weights deterministically.\"\"\"\n",
    "        nn.init.xavier_uniform_(conv_layer.weight)\n",
    "        if conv_layer.bias is not None:\n",
    "            nn.init.constant_(conv_layer.bias, 0)\n",
    "        return conv_layer\n",
    "\n",
    "    def _init_depthwise_separable_conv(self, conv_layer):\n",
    "        \"\"\"Initialize depthwise separable convolution layers.\"\"\"\n",
    "        for m in conv_layer.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "        return conv_layer\n",
    "\n",
    "    def attention(self, q, k, v, shape):\n",
    "        \"\"\"\n",
    "        Perform attention calculation.\n",
    "\n",
    "        Args:\n",
    "            q: Query tensor.\n",
    "            k: Key tensor.\n",
    "            v: Value tensor.\n",
    "            shape: Shape of the input tensor.\n",
    "\n",
    "        Returns:\n",
    "            Attention output tensor.\n",
    "        \"\"\"\n",
    "        B, C, H, W = shape\n",
    "\n",
    "        # Ensure tensors are float for computation\n",
    "        q, k, v = q.float(), k.float(), v.float()\n",
    "\n",
    "        # Scale query\n",
    "        q = q * self.scale\n",
    "\n",
    "        # Compute attention map\n",
    "        att_map = q.transpose(-2, -1) @ k\n",
    "        att_map = att_map.softmax(dim=-1)\n",
    "\n",
    "        # Compute output\n",
    "        out = v @ att_map.transpose(-2, -1)\n",
    "        out = out.view(B, -1, H, W)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the CAA module.\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor of shape (B, C, H, W).\n",
    "\n",
    "        Returns:\n",
    "            Output tensor after applying cascaded atrous attention.\n",
    "        \"\"\"\n",
    "        B, C, H, W = x.shape\n",
    "        x_copy = x\n",
    "\n",
    "        # Initial head processing\n",
    "        all_heads = self.get_begin(x)\n",
    "        multi_layer = all_heads.split([self.head_dim] * self.heads, dim=1)\n",
    "\n",
    "        # Store outputs for each head\n",
    "        all_final = []\n",
    "\n",
    "        # Process each head\n",
    "        for i in range(self.heads):\n",
    "            if i == 0:\n",
    "                # First head\n",
    "                head_ops = self.get_qkv[i](multi_layer[i])\n",
    "                q, k, v = head_ops.split([self.dim, self.dim, self.dim], dim=1)\n",
    "                shape = q.shape\n",
    "                q, k, v = q.flatten(2), k.flatten(2), v.flatten(2)\n",
    "                head_out = self.attention(q, k, v, shape)\n",
    "                head_out = F.interpolate(head_out, size=(H, W), mode='bilinear')\n",
    "                head_out = head_out.view(B, self.dim, H, W)\n",
    "                all_final.append(head_out)\n",
    "            elif i == self.heads - 1:\n",
    "                # Last head\n",
    "                prev_head_proj = self.head_projections[i - 1](all_final[-1])\n",
    "                combined_input = multi_layer[i] + prev_head_proj\n",
    "\n",
    "                head_ops = self.get_qkv[i](combined_input)\n",
    "                q, k, v = head_ops.split([self.dim, self.dim, self.dim], dim=1)\n",
    "                shape = q.shape\n",
    "                q, k, v = q.flatten(2), k.flatten(2), v.flatten(2)\n",
    "                head_out = self.attention(q, k, v, shape)\n",
    "                head_out = F.interpolate(head_out, size=(H, W), mode='bilinear')\n",
    "                head_out = head_out.view(B, self.dim, H, W)\n",
    "                all_final.append(head_out)\n",
    "            else:\n",
    "                # Intermediate heads\n",
    "                prev_head_proj = self.head_projections[i - 1](all_final[-1])\n",
    "                combined_input = multi_layer[i] + prev_head_proj\n",
    "\n",
    "                head_ops = self.get_qkv[i](combined_input)\n",
    "                q, k, v = head_ops.split([self.dim, self.dim, self.dim], dim=1)\n",
    "                shape = q.shape\n",
    "                q, k, v = q.flatten(2), k.flatten(2), v.flatten(2)\n",
    "                head_out = self.attention(q, k, v, shape)\n",
    "                head_out = F.interpolate(head_out, size=(H, W), mode='bilinear')\n",
    "                head_out = head_out.view(B, self.dim, H, W)\n",
    "                all_final.append(head_out)\n",
    "\n",
    "        # Concatenate all head outputs\n",
    "        all_concat = torch.cat(all_final, dim=1)\n",
    "\n",
    "        # Project and add residual connection\n",
    "        x_final = self.proj(all_concat) + x_copy\n",
    "\n",
    "        return self.norm(x_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31Q-9w41a2RR",
   "metadata": {
    "id": "31Q-9w41a2RR"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "OGexxYBhYLzV",
   "metadata": {
    "id": "OGexxYBhYLzV"
   },
   "outputs": [],
   "source": [
    "def analyze_model(model, input_size):\n",
    "    \"\"\"\n",
    "    Comprehensive model analysis function\n",
    "\n",
    "    Parameters:\n",
    "    - model (nn.Module): PyTorch model to analyze\n",
    "    - input_size (tuple): Input tensor size (batch_size, channels, height, width)\n",
    "\n",
    "    Returns:\n",
    "    - dict: Comprehensive model analysis metrics\n",
    "    \"\"\"\n",
    "    # Prepare input tensor\n",
    "    device = next(model.parameters()).device\n",
    "    input_tensor = torch.randn(input_size).to(device)\n",
    "\n",
    "    # 1. Parameter Count\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    # 2. FLOPs and MACs Calculation\n",
    "    try:\n",
    "        flops, params = thop.profile(model, inputs=(input_tensor,), verbose=False)\n",
    "\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"Total Parameters\": total_params,\n",
    "            \"Trainable Parameters\": trainable_params,\n",
    "            \"FLOPs\": flops,\n",
    "            \"MACs\": params,\n",
    "\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in analysis: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "LzoU-PKwYFcn",
   "metadata": {
    "id": "LzoU-PKwYFcn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "Zh-KsKSikohv",
   "metadata": {
    "id": "Zh-KsKSikohv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "import csv\n",
    "import timm\n",
    "import random\n",
    "import thop\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"Set random seed for reproducibility.\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def training(model_name , model_config_name, hyperparams, Module = 'CAGA', pre_trained = True,run = 1 ,EPOCH=35, n_splits=10, max_attempts=8):\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "    # Create a directory for saving CSV files\n",
    "    csv_dir = f'/results/run_{run}'\n",
    "    os.makedirs(csv_dir, exist_ok=True)\n",
    "\n",
    "    models_to_train = [\n",
    "        (model_name, None)\n",
    "    ]\n",
    "\n",
    "    # Create two CSV files - one for successful runs and one for failed attempts\n",
    "    main_csv_path = os.path.join(csv_dir, f'results_{timestamp}_{model_name}.csv')\n",
    "\n",
    "    \n",
    "    # Initialize main results CSV\n",
    "    header = ['Model', 'Seed', 'Fold', 'Accuracy', 'Precision', 'Recall', 'F1'] + \\\n",
    "         [f'{class_name} Accuracy' for class_name in class_labels.keys()] + \\\n",
    "         list(hyperparams.keys())\n",
    "\n",
    "    with open(main_csv_path, 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(header)\n",
    "\n",
    "    # Load data\n",
    "    X_data = torch.Tensor(np.load('/content/drive/MyDrive/X_train_final_multi_10_folds_40_each_equal.npy', allow_pickle=True))\n",
    "    y_data = torch.Tensor(np.load('/content/drive/MyDrive/y_train_final_multi_10_folds_40_each__equal.npy', allow_pickle=True))\n",
    "\n",
    "    # Reshape data for KFold\n",
    "    X_reshaped = X_data.reshape(X_data.shape[0] * X_data.shape[1], *X_data.shape[2:])\n",
    "    y_reshaped = y_data.reshape(y_data.shape[0] * y_data.shape[1], *y_data.shape[2:])\n",
    "\n",
    "    for model_name, custom_head in models_to_train:\n",
    "        accuracy_dict_train = {}\n",
    "        accuracy_dict_val = {}\n",
    "        loss_dict_train = {}\n",
    "        loss_dict_val = {}\n",
    "        accu = []\n",
    "\n",
    "        accuracy_avg = 0\n",
    "        precision_avg = 0\n",
    "        recall_avg = 0\n",
    "        f1_avg = 0\n",
    "\n",
    "        class_total_test_acc = {class_name: 0 for class_name in class_labels.keys()}\n",
    "\n",
    "        epoch_number = 0\n",
    "\n",
    "\n",
    "\n",
    "        # Seed control for entire cross-validation\n",
    "\n",
    "        current_seed = 59\n",
    "\n",
    "\n",
    "        # Set seed for this attempt\n",
    "        set_seed(current_seed)\n",
    "\n",
    "        # Initialize KFold\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=current_seed)\n",
    "\n",
    "\n",
    "            # Iterate through KFold splits\n",
    "        for fold, (train_val_index, test_index) in enumerate(kf.split(X_reshaped )):\n",
    "            print(f\"\\nStarting Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "            # if fold<=5:\n",
    "            #   continue\n",
    "\n",
    "            # Reset epoch counter for each fold\n",
    "            epoch_number = 0\n",
    "            print(fold)\n",
    "# Split the entire dataset into train_val and test\n",
    "            X_train_val, X_test = X_reshaped[train_val_index], X_reshaped[test_index]\n",
    "            y_train_val, y_test = y_reshaped[train_val_index], y_reshaped[test_index]\n",
    "\n",
    "            # Create a validation split within the training data\n",
    "            val_size = int(len(X_train_val) * 0.2)  # 20% validation\n",
    "            X_train = X_train_val[:-val_size]\n",
    "            y_train = y_train_val[:-val_size]\n",
    "            X_val = X_train_val[-val_size:]\n",
    "            y_val = y_train_val[-val_size:]\n",
    "\n",
    "\n",
    "\n",
    "            # Normalization (you may need to adjust this based on your existing norm function)\n",
    "            X_train, X_val, X_test = norm(X_train, X_val, X_test)\n",
    "\n",
    "            print(\"Xtrain\" , X_train.shape)\n",
    "            print(\"Xval\" , X_val.shape)\n",
    "            print(\"Xtest\" , X_test.shape)\n",
    "\n",
    "            # Create DataLoaders\n",
    "            training_loader = DataLoader(\n",
    "                TensorDataset(torch.Tensor(X_train).to(device), torch.Tensor(y_train).to(device)),\n",
    "                batch_size=16,\n",
    "                shuffle=True\n",
    "            )\n",
    "            validation_loader = DataLoader(\n",
    "                TensorDataset(torch.Tensor(X_val).to(device), torch.Tensor(y_val).to(device)),\n",
    "                batch_size=16,\n",
    "                shuffle=True\n",
    "            )\n",
    "            test_loader = DataLoader(\n",
    "                TensorDataset(torch.Tensor(X_test).to(device), torch.Tensor(y_test).to(device)),\n",
    "                batch_size=8,\n",
    "                shuffle=False\n",
    "            )\n",
    "\n",
    "            # Model setup (keep your existing model creation code)\n",
    "            \n",
    "            model = timm.create_model(model_config_name, pretrained= pre_trained) #for ablation turn pre-trained to False\n",
    "            if Module == 'CAGA':\n",
    "                replace_context_modules(model, CAGA, dilation = hyperparams['dilation']) # comment this for all other models apart for efficientViT-CAGA\n",
    "            elif Module == 'CAA':\n",
    "                replace_context_modules(model, CAGA, dilation = hyperparams['dilation'])\n",
    "            elif Module == 'CAGA_nocascading_in_CAA':\n",
    "                replace_context_modules(model, CAGA_nocascading_in_CAA, dilation = hyperparams['dilation'])\n",
    "            change_classifier(model,model_config_name, dropout=0.111975, neurons1=hyperparams['neurons1'], neurons2=hyperparams['neurons2'], neurons3=768, neurons4=512, n_layers= hyperparams['n_layers'])\n",
    "            model.to(device)\n",
    "\n",
    "            print(model)\n",
    "            # input_size = (1, 3, 224, 224)  # Batch size, Channels, Height, Width\n",
    "            # analysis_results = analyze_model(model, input_size)\n",
    "            # if analysis_results:\n",
    "            #   print(\"Model Analysis Results:\")\n",
    "            #   for key, value in analysis_results.items():\n",
    "            #       print(f\"{key}: {value}\")\n",
    "\n",
    "\n",
    "\n",
    "            alpha = torch.Tensor([0.1412, 0.0992, 0.1409, 0.0872]).to(device)\n",
    "            loss_fn = torch.nn.BCELoss()\n",
    "            if hyperparams['loss']=='BCE':\n",
    "              loss_fn1 = torch.nn.BCELoss()\n",
    "            elif hyperparams['loss']=='CE':\n",
    "            #loss_fn1 = FocalCELoss(alpha = alpha)\n",
    "              loss_fn1 = torch.nn.CrossEntropyLoss()\n",
    "            elif hyperparams['loss']=='FCE':\n",
    "              loss_fn1 = FocalCELoss(alpha = alpha)\n",
    "            w = 1\n",
    "            optimizer = torch.optim.AdamW(params=model.parameters(), lr=hyperparams['lr'], weight_decay = hyperparams['weight_decay'])\n",
    "            scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.96)\n",
    "            early_stopper = EarlyStopper(patience=9, min_delta=0)\n",
    "\n",
    "            print(f'Model {fold}:')\n",
    "\n",
    "            for epoch in range(EPOCH):\n",
    "                print(f\"Learning rate: {optimizer.param_groups[0]['lr']}\")\n",
    "                print(f'EPOCH {epoch_number + 1}:')\n",
    "\n",
    "                model.train(True)\n",
    "                avg_loss, train_accuracy, right, *class_accuracies_train = train_one_epoch(model, epoch_number, fold, training_loader, loss_fn, loss_fn1, w, optimizer, loss_dict_train)\n",
    "\n",
    "                print(f\"Average loss: {avg_loss}\")\n",
    "\n",
    "                running_vloss = 0.0\n",
    "                model.eval()\n",
    "                vright_total = 0\n",
    "                total_val = 0\n",
    "\n",
    "                class_totals_val = {class_name: 0 for class_name in class_labels.keys()}\n",
    "                class_rights_val = {class_name: 0 for class_name in class_labels.keys()}\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    for i, vdata in enumerate(validation_loader):\n",
    "                        vinputs, vlabels = vdata\n",
    "                        total_val += vinputs.shape[0]\n",
    "\n",
    "                        voutputs = model(vinputs)\n",
    "                        vloss = (1-w) * loss_fn(voutputs, vlabels) + w * loss_fn1(voutputs, vlabels)\n",
    "\n",
    "                        class_totals_batch = cal_total(vlabels)\n",
    "                        vright, *class_rights_batch = acc_eval(voutputs, vlabels, classwise=True)\n",
    "\n",
    "                        vright_total += vright\n",
    "\n",
    "                        for j, class_name in enumerate(class_labels.keys()):\n",
    "                            class_totals_val[class_name] += class_totals_batch[j]\n",
    "                            class_rights_val[class_name] += class_rights_batch[j]\n",
    "\n",
    "                        running_vloss += vloss\n",
    "\n",
    "                avg_vloss = running_vloss / (i + 1)\n",
    "                print(f\"Validation loss: {avg_vloss}\")\n",
    "\n",
    "                class_accuracies_val = {}\n",
    "                for class_name in class_labels.keys():\n",
    "                    if class_totals_val[class_name] == 0:\n",
    "                        class_accuracies_val[class_name] = None\n",
    "                    else:\n",
    "                        class_accuracies_val[class_name] = class_rights_val[class_name] / class_totals_val[class_name]\n",
    "\n",
    "                scheduler.step()\n",
    "\n",
    "                val_acc = vright_total / total_val\n",
    "\n",
    "                print(f\"Validation accuracy: {val_acc}\")\n",
    "                print(f'LOSS train {avg_loss} valid {avg_vloss}')\n",
    "                print(f'Right train {right} valid {vright_total}')\n",
    "                print(f'Accuracy train {train_accuracy} valid {val_acc}')\n",
    "\n",
    "                print('---------->classwise<-----------')\n",
    "                for class_name in class_labels.keys():\n",
    "                    print(f'Accuracy {class_name} train {class_accuracies_train[list(class_labels.keys()).index(class_name)]} valid {class_accuracies_val[class_name]}')\n",
    "\n",
    "                epoch_number += 1\n",
    "                early = early_stopper.early_stop(val_acc)\n",
    "                print(\"Current early_stop count\", early[1])\n",
    "                if early[0]:\n",
    "                    print('Early stopping triggered')\n",
    "                    break\n",
    "\n",
    "\n",
    "            # After testing, check accuracy\n",
    "            with torch.no_grad():\n",
    "              acc, precision, recall, f1, *class_accuracies_test = test(model, test_loader, fold)\n",
    "\n",
    "\n",
    "              print('##########################################################')\n",
    "              print(f'Accuracy test {acc}')\n",
    "              print(f'Precision test {precision}')\n",
    "              print(f'Recall test {recall}')\n",
    "              print(f'F1 test {f1}')\n",
    "\n",
    "              print('---------->classwise test<-----------')\n",
    "              for i, class_name in enumerate(class_labels.keys()):\n",
    "                  print(f'Accuracy {class_name} test {class_accuracies_test[i]}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "              # Save results to CSV (modify to include seed)\n",
    "              # Save results to CSV (including hyperparameters)\n",
    "              row = [model_name, current_seed, fold, acc, precision, recall, f1] + \\\n",
    "                    class_accuracies_test + \\\n",
    "                    list(hyperparams.values())\n",
    "\n",
    "              with open(main_csv_path, 'a', newline='') as csvfile:\n",
    "                  csvwriter = csv.writer(csvfile)\n",
    "                  csvwriter.writerow(row)\n",
    "\n",
    "              # Accumulate results\n",
    "              accuracy_avg += acc\n",
    "              precision_avg += precision\n",
    "              recall_avg += recall\n",
    "              f1_avg += f1\n",
    "\n",
    "              for i, class_name in enumerate(class_labels.keys()):\n",
    "                  class_total_test_acc[class_name] += class_accuracies_test[i]\n",
    "\n",
    "        # If we've made it through all folds, break the seed attempt loop\n",
    "        print(f\"\\n=== Successfully completed all folds with seed {current_seed} ===\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Calculate and log final averages\n",
    "        accuracy_avg /= n_splits\n",
    "        precision_avg /= n_splits\n",
    "        recall_avg /= n_splits\n",
    "        f1_avg /= n_splits\n",
    "\n",
    "        for class_name in class_labels.keys():\n",
    "            class_total_test_acc[class_name] /= n_splits\n",
    "\n",
    "        print(f'Average results for {model_name}:')\n",
    "        print(f'Average Accuracy test {accuracy_avg}')\n",
    "        print(f'Average precision test {precision_avg}')\n",
    "        print(f'Average recall test {recall_avg}')\n",
    "        print(f'Average f1 test {f1_avg}')\n",
    "\n",
    "        print('---------->classwise test Average<-----------')\n",
    "        for class_name, avg_acc in class_total_test_acc.items():\n",
    "            print(f'Average {class_name} Accuracy test {avg_acc}')\n",
    "\n",
    "        # Save average results to CSV\n",
    "        # Save average results with hyperparameters\n",
    "        avg_row = [model_name,current_seed,'Average', accuracy_avg, precision_avg, recall_avg, f1_avg] + \\\n",
    "                  list(class_total_test_acc.values()) + \\\n",
    "                  list(hyperparams.values())\n",
    "\n",
    "        with open(main_csv_path, 'a', newline='') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile)\n",
    "            csvwriter.writerow(avg_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u2nLIZK9q5z5",
   "metadata": {
    "id": "u2nLIZK9q5z5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
