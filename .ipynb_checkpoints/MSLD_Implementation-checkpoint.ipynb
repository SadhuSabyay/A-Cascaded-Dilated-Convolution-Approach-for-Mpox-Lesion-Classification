{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "24ecd3f3-eed2-4a9a-9b07-2dd4c5534e85",
      "metadata": {
        "id": "24ecd3f3-eed2-4a9a-9b07-2dd4c5534e85"
      },
      "source": [
        "# Mpox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dfc3ad59-fdc9-4094-9083-f8ff5539cbec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfc3ad59-fdc9-4094-9083-f8ff5539cbec",
        "outputId": "0ceb4a23-3ef0-46ad-af19-dac4438a972e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torchvision.models as tvm\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import os\n",
        "\n",
        "import torch.optim as to\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset\n",
        "\n",
        "%run model.ipynb\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0db07df5-0b5d-450b-b882-19787ec54760",
      "metadata": {
        "id": "0db07df5-0b5d-450b-b882-19787ec54760"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6e9e9770-bec6-432e-aaf5-651e7674357c",
      "metadata": {
        "id": "6e9e9770-bec6-432e-aaf5-651e7674357c"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "169f9c9f-df3d-4853-a46d-7a8f717d1b25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "169f9c9f-df3d-4853-a46d-7a8f717d1b25",
        "outputId": "5283c9bf-1706-4dba-9841-a97f4a3157b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0.12\n"
          ]
        }
      ],
      "source": [
        "import timm\n",
        "print(timm.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4b6e34ba-11f7-4dc4-89f3-60e1cde88227",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b6e34ba-11f7-4dc4-89f3-60e1cde88227",
        "outputId": "59a7f7ff-e81b-401f-bfc6-4ce7c5f308f9",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data shape: torch.Size([2234, 3, 224, 224])\n",
            "Training labels shape: torch.Size([2234, 2])\n",
            "Validation data shape: torch.Size([638, 3, 224, 224])\n",
            "Validation labels shape: torch.Size([638, 2])\n",
            "Test data shape: torch.Size([320, 3, 224, 224])\n",
            "Test labels shape: torch.Size([320, 2])\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from typing import Tuple, List\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class MedicalImagePreprocessor:\n",
        "    \"\"\"\n",
        "    Preprocessor for medical image datasets with stratified train-val-test splitting.\n",
        "    Generates one-hot encoded labels.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        mpox_dir: str,\n",
        "        others_dir: str,\n",
        "        image_size: Tuple[int, int] = (224, 224),\n",
        "        random_seed: int = 42\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initialize preprocessor with mpox and others image directories.\n",
        "\n",
        "        Args:\n",
        "            mpox_dir (str): Path to mpox image directory\n",
        "            others_dir (str): Path to other images directory\n",
        "            image_size (Tuple[int, int], optional): Resize dimensions. Defaults to (224, 224)\n",
        "        \"\"\"\n",
        "        self.mpox_dir = mpox_dir\n",
        "        self.others_dir = others_dir\n",
        "        self.image_size = image_size\n",
        "        self.random_seed = random_seed\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize(image_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406],  # Standard ImageNet normalization\n",
        "                std=[0.229, 0.224, 0.225]\n",
        "            )\n",
        "        ])\n",
        "\n",
        "    def _collect_images(self) -> Tuple[List[str], List[int]]:\n",
        "        \"\"\"\n",
        "        Collect image paths and corresponding labels from both directories.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of image paths and their labels\n",
        "        \"\"\"\n",
        "        image_paths = []\n",
        "        labels = []\n",
        "\n",
        "        # Collect mpox images (label 1)\n",
        "        for filename in os.listdir(self.mpox_dir):\n",
        "            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                image_paths.append(os.path.join(self.mpox_dir, filename))\n",
        "                labels.append(1)  # Mpox positive\n",
        "\n",
        "        # Collect other images (label 0)\n",
        "        for filename in os.listdir(self.others_dir):\n",
        "            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                image_paths.append(os.path.join(self.others_dir, filename))\n",
        "                labels.append(0)  # Mpox negative\n",
        "\n",
        "        return image_paths, labels\n",
        "\n",
        "    def _load_image(self, image_path: str) -> Tensor:\n",
        "        \"\"\"\n",
        "        Load and preprocess a single image.\n",
        "\n",
        "        Args:\n",
        "            image_path (str): Full path to image file\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Preprocessed image tensor\n",
        "        \"\"\"\n",
        "        with Image.open(image_path).convert('RGB') as img:\n",
        "            return self.transform(img)\n",
        "\n",
        "    def prepare_dataset(self) -> Tuple[Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]:\n",
        "        \"\"\"\n",
        "        Prepare dataset with stratified 70/20/10 train/val/test split.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of PyTorch tensors: (X_train, y_train, X_val, y_val, X_test, y_test)\n",
        "        \"\"\"\n",
        "        # Collect image paths and labels\n",
        "        image_paths, labels = self._collect_images()\n",
        "\n",
        "        # Validate dataset\n",
        "        if not image_paths:\n",
        "            raise ValueError(\"No valid images found in the specified directories.\")\n",
        "\n",
        "        # Numpy conversion for stratified splitting\n",
        "        image_paths = np.array(image_paths)\n",
        "        labels = np.array(labels)\n",
        "\n",
        "        # Stratified splits\n",
        "        X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "            image_paths, labels,\n",
        "            test_size=0.3,  # 70% train\n",
        "            stratify=labels,\n",
        "            random_state=self.random_seed\n",
        "        )\n",
        "\n",
        "        X_val, X_test, y_val, y_test = train_test_split(\n",
        "            X_temp, y_temp,\n",
        "            test_size=1/3,  # 20% validation, 10% test\n",
        "            stratify=y_temp,\n",
        "            random_state=self.random_seed\n",
        "        )\n",
        "\n",
        "        # Preprocessing images\n",
        "        X_train_tensors = torch.stack([self._load_image(path) for path in X_train])\n",
        "        X_val_tensors = torch.stack([self._load_image(path) for path in X_val])\n",
        "        X_test_tensors = torch.stack([self._load_image(path) for path in X_test])\n",
        "\n",
        "        # One-hot encoding for labels\n",
        "        y_train_tensors = torch.nn.functional.one_hot(torch.tensor(y_train), num_classes=2).float()\n",
        "        y_val_tensors = torch.nn.functional.one_hot(torch.tensor(y_val), num_classes=2).float()\n",
        "        y_test_tensors = torch.nn.functional.one_hot(torch.tensor(y_test), num_classes=2).float()\n",
        "\n",
        "        return (X_train_tensors, y_train_tensors,\n",
        "                X_val_tensors, y_val_tensors,\n",
        "                X_test_tensors, y_test_tensors)\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Example usage demonstrating dataset preparation.\n",
        "    \"\"\"\n",
        "    mpox_dir = '/content/MSLD/Augmented Images/Augmented Images/Monkeypox_augmented'\n",
        "    others_dir = '/content/MSLD/Augmented Images/Augmented Images/Others_augmented'\n",
        "\n",
        "    preprocessor = MedicalImagePreprocessor(mpox_dir, others_dir)\n",
        "\n",
        "\n",
        "    X_train, y_train, X_val, y_val, X_test, y_test = preprocessor.prepare_dataset()\n",
        "\n",
        "    # Logging data shapes\n",
        "    print(f\"Training data shape: {X_train.shape}\")\n",
        "    print(f\"Training labels shape: {y_train.shape}\")\n",
        "    print(f\"Validation data shape: {X_val.shape}\")\n",
        "    print(f\"Validation labels shape: {y_val.shape}\")\n",
        "    print(f\"Test data shape: {X_test.shape}\")\n",
        "    print(f\"Test labels shape: {y_test.shape}\")\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "     X_train, y_train, X_val, y_val, X_test, y_test = main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "nhLsp_hgegRP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhLsp_hgegRP",
        "outputId": "0e3d3165-294c-4bbe-e173-805d0d97ee3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 0.])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "54bd7adf-ca24-465f-8509-95f51cb985a3",
      "metadata": {
        "id": "54bd7adf-ca24-465f-8509-95f51cb985a3"
      },
      "outputs": [],
      "source": [
        "def evaluate(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Evaluates the performance of a classification model using precision, recall, and F1-score.\n",
        "\n",
        "    Parameters:\n",
        "    y_true (list or array-like): True labels.\n",
        "    y_pred (list or array-like): Predicted labels by the model.\n",
        "\n",
        "    Returns:\n",
        "    tuple: Precision, Recall, and F1-Score, calculated using macro averaging.\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate precision score using macro averaging (treats all classes equally)\n",
        "    precision = precision_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    # Calculate recall score using macro averaging\n",
        "    recall = recall_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    # Calculate F1-score using macro averaging\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    # Return the calculated metrics as a tuple\n",
        "    return precision, recall, f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0fc926ec-69bc-4c16-bf11-dace61e6cb2a",
      "metadata": {
        "id": "0fc926ec-69bc-4c16-bf11-dace61e6cb2a",
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "52be10e4-af33-410a-b1fe-c63547799b89",
      "metadata": {
        "id": "52be10e4-af33-410a-b1fe-c63547799b89",
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "267f1e3c-672e-4832-9bc0-ec2fe0bff61e",
      "metadata": {
        "id": "267f1e3c-672e-4832-9bc0-ec2fe0bff61e",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def replace_context_modules(model, Module, dilation):\n",
        "    \"\"\"\n",
        "    Replaces the context_module in specific blocks of a model's fourth stage with a custom module.\n",
        "\n",
        "    Parameters:\n",
        "    model: The model containing stages and blocks where replacements are to be made.\n",
        "    Module: Custom module to replace the existing context_module.\n",
        "    seed: Random seed for reproducibility in the custom module.\n",
        "    \"\"\"\n",
        "\n",
        "    # Access the fourth stage (index 3) of the model\n",
        "    stage = model.stages[3]\n",
        "\n",
        "    # Loop through blocks 1 to 6 (indices 1 to 6) in the fourth stage\n",
        "    for i in range(1, 7):\n",
        "        block = stage.blocks[i]  # Access the current block\n",
        "\n",
        "        # Extract the number of input channels from the original context_module\n",
        "        in_channels = block.context_module.main.qkv.conv.in_channels\n",
        "\n",
        "        # Extract the number of output channels from the original context_module\n",
        "        out_channels = block.context_module.main.proj.conv.out_channels\n",
        "\n",
        "        # Replace the existing context_module with a new custom module\n",
        "        block.context_module = nn.Sequential(\n",
        "            Module(in_channels, nn.ReLU, dilation=dilation)  # Initialize custom module with required parameters\n",
        "        )\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "da9c2f8e-8290-4a41-a05e-1f2d611dc085",
      "metadata": {
        "id": "da9c2f8e-8290-4a41-a05e-1f2d611dc085"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "464db3fe-8de7-423f-bbfd-41e7fe6c5965",
      "metadata": {
        "id": "464db3fe-8de7-423f-bbfd-41e7fe6c5965"
      },
      "outputs": [],
      "source": [
        "\n",
        "def change_classifier(model, model_name, num_classes=2, dropout=0.5,\n",
        "                     neurons1=4096, neurons2=1024, neurons3=256, neurons4=512, n_layers=2):\n",
        "    \"\"\"\n",
        "    Change the classifier head of various vision models\n",
        "\n",
        "    Args:\n",
        "        model: The base model to modify\n",
        "        model_name: Name/type of the model to determine input features\n",
        "        num_classes: Number of output classes\n",
        "        dropout: Dropout rate\n",
        "        neurons1-4: Number of neurons in each layer\n",
        "        n_layers: Number of layers in classifier (1-4)\n",
        "    \"\"\"\n",
        "    # Define input features based on model architecture\n",
        "    input_features = {\n",
        "        'resnet101.a1_in1k': 2048,\n",
        "        'deit3_medium_patch16_224': 512,\n",
        "        'coatnet_1_rw_224.sw_in1k': 768,\n",
        "        'mobilenetv3_large_100.ra_in1k': 1280,\n",
        "        'vit_base_patch16_224' : 768,\n",
        "        'efficientvit_l1.r224_in1k': 3072\n",
        "    }\n",
        "\n",
        "    in_features = input_features.get(model_name, 3072)  # Default to 3072 if model not found\n",
        "\n",
        "    # Create the classifier based on number of layers\n",
        "    if n_layers == 1:\n",
        "        classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features, neurons1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(neurons1, num_classes),\n",
        "            nn.Sigmoid() if num_classes == 1 else nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    elif n_layers == 2:\n",
        "        classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features, neurons1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(neurons1, neurons2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(neurons2, num_classes),\n",
        "            nn.Sigmoid() if num_classes == 1 else nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    elif n_layers == 3:\n",
        "        classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features, neurons1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(neurons1, neurons2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(neurons2, neurons3),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(neurons3, num_classes),\n",
        "            nn.Sigmoid() if num_classes == 1 else nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    else:  # 4 layers\n",
        "        classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features, neurons1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(neurons1, neurons2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(neurons2, neurons3),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(neurons3, neurons4),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(neurons4, num_classes),\n",
        "            nn.Sigmoid() if num_classes == 1 else nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    # Determine where to attach the classifier based on model type\n",
        "    if hasattr(model, 'head'):\n",
        "      if hasattr(model.head, 'classifier'):\n",
        "        model.head.classifier = classifier\n",
        "\n",
        "      elif hasattr(model.head, 'fc'):\n",
        "        model.head.fc = classifier\n",
        "      else:\n",
        "         model.head = classifier\n",
        "    elif hasattr(model, 'fc'):\n",
        "      model.fc = classifier\n",
        "    elif hasattr(model, 'classifier'):\n",
        "      model.classifier = classifier\n",
        "\n",
        "\n",
        "\n",
        "    else:\n",
        "        raise AttributeError(\"Model structure not supported. Cannot find classifier or head attribute.\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "5c13559c-2e87-474d-9769-d84da558d30a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c13559c-2e87-474d-9769-d84da558d30a",
        "outputId": "12aadaf4-7312-4db2-f098-96fa32250e83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device\n",
        "\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a3d68765-0e15-4956-b4d6-d96b8da4f510",
      "metadata": {
        "id": "a3d68765-0e15-4956-b4d6-d96b8da4f510"
      },
      "outputs": [],
      "source": [
        "class_labels = {\n",
        "    'monkey_pox' : [0.,1.],\n",
        "    'other': [1.,0.]\n",
        "}\n",
        "# def acc_eval(outputs, labels, classwise=False):\n",
        "#     predicted = (outputs > 0.5).float()\n",
        "#     correct = (predicted == labels).float()\n",
        "#     right = correct.sum().item()\n",
        "\n",
        "#     if not classwise:\n",
        "#         return right\n",
        "#     else:\n",
        "#         class_rights = {\n",
        "#             'Other': ((1 - labels) * correct).sum().item(),\n",
        "#             'Monkeypox': (labels * correct).sum().item()\n",
        "#         }\n",
        "#         return (right, class_rights['Other'], class_rights['Monkeypox'])\n",
        "\n",
        "def acc_eval(outputs, labels, classwise=False):\n",
        "    \"\"\"\n",
        "    Evaluate accuracy of model predictions.\n",
        "\n",
        "    Args:\n",
        "        outputs (torch.Tensor): Model predictions (one-hot encoded).\n",
        "        labels (torch.Tensor): Ground truth labels (one-hot encoded).\n",
        "        classwise (bool): If True, calculate and return class-wise accuracy.\n",
        "\n",
        "    Returns:\n",
        "        int: Total correct predictions if classwise=False.\n",
        "        tuple: Total correct predictions and class-wise counts if classwise=True.\n",
        "    \"\"\"\n",
        "    right = 0  # Counter for correct predictions\n",
        "    class_rights = {class_name: 0 for class_name in class_labels.keys()}  # Initialize class-wise correct counters\n",
        "\n",
        "    for j in range(outputs.shape[0]):  # Loop over all predictions in the batch\n",
        "        max_value = torch.max(outputs[j])  # Get the maximum value in the current prediction\n",
        "        outputs[j] = (outputs[j] == max_value).float()  # Convert to one-hot representation by retaining the max value index\n",
        "        if torch.all(outputs[j].eq(labels[j])):  # Check if the prediction matches the ground truth\n",
        "            right += 1  # Increment total correct counter\n",
        "            if classwise:  # If classwise evaluation is required\n",
        "                label_list = labels[j].detach().cpu().tolist()  # Convert label tensor to list for comparison\n",
        "                for class_name, class_label in class_labels.items():  # Loop through each class label\n",
        "                    if label_list == class_label:  # Check if the ground truth matches the current class label\n",
        "                        class_rights[class_name] += 1  # Increment correct counter for the class\n",
        "                        break  # Exit the loop once the class is identified\n",
        "    if not classwise:  # Return total correct predictions if classwise=False\n",
        "        return right\n",
        "    else:  # Return total correct predictions and class-wise correct counts if classwise=True\n",
        "        return (right, *class_rights.values())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "84713b2a-975b-4bbc-b7a8-ce2390295a7a",
      "metadata": {
        "id": "84713b2a-975b-4bbc-b7a8-ce2390295a7a"
      },
      "outputs": [],
      "source": [
        "def cal_total(labels):\n",
        "    \"\"\"\n",
        "    Calculate the total count of labels for each class.\n",
        "\n",
        "    Args:\n",
        "        labels (torch.Tensor): Ground truth labels (one-hot encoded).\n",
        "\n",
        "    Returns:\n",
        "        tuple: Total counts for each class, in the order of class_labels keys.\n",
        "    \"\"\"\n",
        "    # Initialize a dictionary to store the total count for each class\n",
        "    class_totals = {class_name: 0 for class_name in class_labels.keys()}\n",
        "\n",
        "    for j in range(labels.shape[0]):  # Loop over all labels in the batch\n",
        "        label_list = labels[j].detach().cpu().tolist()  # Convert label tensor to a list\n",
        "        for class_name, class_label in class_labels.items():  # Iterate through all class labels\n",
        "            if label_list == class_label:  # Check if the label matches the current class\n",
        "                class_totals[class_name] += 1  # Increment the count for the matched class\n",
        "                break  # Exit the loop once the class is identified\n",
        "\n",
        "    # Return the total counts for each class as a tuple\n",
        "    return tuple(class_totals.values())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "51f6178f-64cd-4f99-bbd3-e90c2303332c",
      "metadata": {
        "id": "51f6178f-64cd-4f99-bbd3-e90c2303332c"
      },
      "outputs": [],
      "source": [
        "def norm(X_train, X_val, X_test):\n",
        "    \"\"\"\n",
        "    Normalize training, validation, and test datasets using training set statistics.\n",
        "    \"\"\"\n",
        "    meanx = X_train.mean()  # Calculate training set mean\n",
        "    stdx = X_train.std()    # Calculate training set std\n",
        "\n",
        "    # Normalize datasets using training set mean and std\n",
        "    X_train = (X_train - meanx) / stdx\n",
        "    X_valid = (X_val - meanx) / stdx\n",
        "    X_test = (X_test - meanx) / stdx\n",
        "\n",
        "    return X_train, X_valid, X_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "e0542860-41f2-45b3-9c68-425647660d4f",
      "metadata": {
        "id": "e0542860-41f2-45b3-9c68-425647660d4f",
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b7d58417-8fd8-40e4-914b-49ee9f46a3c1",
      "metadata": {
        "id": "b7d58417-8fd8-40e4-914b-49ee9f46a3c1"
      },
      "outputs": [],
      "source": [
        "def test(model, training_loader, model_num):\n",
        "    \"\"\"\n",
        "    Evaluate the model on the test dataset and compute accuracy, precision, recall, F1 score,\n",
        "    and per-class accuracies.\n",
        "    \"\"\"\n",
        "    right_total = 0  # Total correct predictions\n",
        "    total = 0  # Total number of samples\n",
        "    out = []  # List to store predicted labels\n",
        "    lab = []  # List to store true labels\n",
        "    class_totals = {class_name: 0 for class_name in class_labels.keys()}  # Per-class sample counts\n",
        "    class_rights = {class_name: 0 for class_name in class_labels.keys()}  # Per-class correct predictions\n",
        "\n",
        "    for i, data in enumerate(tqdm(training_loader)):  # Iterate over the training data\n",
        "        inputs, labels = data  # Get inputs and labels\n",
        "        total += inputs.shape[0]  # Update total samples\n",
        "\n",
        "        outputs = model(inputs)  # Get model predictions\n",
        "\n",
        "        # Get per-class totals and correct predictions\n",
        "        class_totals_batch = cal_total(labels)\n",
        "        right, *class_rights_batch = acc_eval(outputs, labels, classwise=True)\n",
        "\n",
        "        right_total += right  # Update total correct predictions\n",
        "        for i, class_name in enumerate(class_labels.keys()):  # Update per-class totals and rights\n",
        "            class_totals[class_name] += class_totals_batch[i]\n",
        "            class_rights[class_name] += class_rights_batch[i]\n",
        "\n",
        "        # Convert outputs and labels to numpy arrays for evaluation\n",
        "        outputs = np.array(outputs.detach().cpu(), dtype='object')\n",
        "        labels = np.array(labels.detach().cpu(), dtype='object')\n",
        "\n",
        "        out.extend(np.argmax(outputs, axis=1))  # Store predicted labels\n",
        "        lab.extend(np.argmax(labels, axis=1))  # Store true labels\n",
        "\n",
        "    accuracy = right_total / total  # Calculate overall accuracy\n",
        "    class_accuracies = {class_name: class_rights[class_name] / class_totals[class_name]\n",
        "                        if class_totals[class_name] > 0 else 0\n",
        "                        for class_name in class_labels.keys()}  # Calculate per-class accuracies\n",
        "\n",
        "    precision, recall, f1 = evaluate(out, lab)  # Evaluate precision, recall, and F1 score\n",
        "\n",
        "    print(\"Accuracy:\", accuracy)  # Print overall accuracy\n",
        "    print(\"Total Right:\", right_total)  # Print total correct predictions\n",
        "    for class_name, class_accuracy in class_accuracies.items():  # Print per-class accuracy\n",
        "        print(f\"{class_name} Accuracy: {class_accuracy}\")\n",
        "\n",
        "    return (accuracy, precision, recall, f1, *class_accuracies.values())  # Return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "edc659e3-125f-4b3f-961c-5175759be21b",
      "metadata": {
        "id": "edc659e3-125f-4b3f-961c-5175759be21b"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, epoch_index, model_num, training_loader, loss_fn, loss_fn1, w, optimizer, loss_dict_train):\n",
        "    \"\"\"\n",
        "    Train the model for one epoch, computing losses and accuracies, and updating model weights.\n",
        "\n",
        "    Args:\n",
        "        model: The neural network model to train.\n",
        "        epoch_index: The index of the current epoch.\n",
        "        model_num: Identifier for the model (used for loss tracking).\n",
        "        training_loader: DataLoader object for training dataset.\n",
        "        loss_fn: Primary loss function used for training.\n",
        "        loss_fn1: Secondary loss function used for training (combined with loss_fn).\n",
        "        w: Weighting factor for combining loss_fn and loss_fn1.\n",
        "        optimizer: Optimizer to update model parameters.\n",
        "        loss_dict_train: Dictionary to track losses for the training process.\n",
        "\n",
        "    Returns:\n",
        "        last_loss: The average loss for the last batch in the epoch.\n",
        "        overall_accuracy: The overall accuracy of the model on the training dataset.\n",
        "        right_total: Total number of correct predictions in the epoch.\n",
        "        class_accuracies: Per-class accuracy for each class in the dataset.\n",
        "    \"\"\"\n",
        "    running_loss = 0.  # To track cumulative loss for the current epoch\n",
        "    last_loss = 0.  # To store the average loss for the last batch\n",
        "    right_total = 0  # Total correct predictions\n",
        "    total = 0  # Total samples processed\n",
        "\n",
        "    class_totals = {class_name: 0 for class_name in class_labels.keys()}  # Store count of each class in the batch\n",
        "    class_rights = {class_name: 0 for class_name in class_labels.keys()}  # Store correct predictions for each class\n",
        "\n",
        "    # Iterate through batches in the training set\n",
        "    for i, data in enumerate(tqdm(training_loader)):\n",
        "        inputs, labels = data  # Get input images and corresponding labels\n",
        "        optimizer.zero_grad()  # Reset gradients to zero before backpropagation\n",
        "        outputs = model(inputs)  # Get model predictions\n",
        "\n",
        "        total += inputs.shape[0]  # Update the total number of samples processed\n",
        "        # Compute the loss as a weighted combination of the two loss functions\n",
        "        loss = (1-w) * loss_fn(outputs, labels) + w * loss_fn1(outputs, labels)\n",
        "        loss.backward()  # Backpropagate the loss\n",
        "        optimizer.step()  # Update the model weights using the optimizer\n",
        "\n",
        "        # Get per-class totals and correct predictions\n",
        "        class_totals_batch = cal_total(labels)\n",
        "        right, *class_rights_batch = acc_eval(outputs, labels, classwise=True)\n",
        "\n",
        "        right_total += right  # Update the total correct predictions\n",
        "        # Update per-class totals and correct predictions\n",
        "        for j, class_name in enumerate(class_labels.keys()):\n",
        "            class_totals[class_name] += class_totals_batch[j]\n",
        "            class_rights[class_name] += class_rights_batch[j]\n",
        "\n",
        "        running_loss += loss.item()  # Add current batch loss to running total\n",
        "        # Print the average loss for every 10 batches\n",
        "        if i % 10 == 9:\n",
        "            last_loss = running_loss / 10  # Calculate the average loss for the last 10 batches\n",
        "            print(f'  batch {i + 1} loss: {last_loss}')\n",
        "            running_loss = 0.  # Reset running loss for the next set of batches\n",
        "\n",
        "    # Calculate per-class accuracies\n",
        "    print(\"Class totals:\", class_totals)\n",
        "    class_accuracies = {}\n",
        "    for class_name in class_labels.keys():\n",
        "        if class_totals[class_name] == 0:\n",
        "            class_accuracies[class_name] = None  # No data for this class\n",
        "        else:\n",
        "            class_accuracies[class_name] = class_rights[class_name] / class_totals[class_name]  # Calculate class accuracy\n",
        "\n",
        "    # Calculate overall accuracy\n",
        "    overall_accuracy = right_total / total if total > 0 else None\n",
        "\n",
        "    # Return the last loss, overall accuracy, total correct predictions, and class-wise accuracies\n",
        "    return (last_loss, overall_accuracy, right_total,\n",
        "            *[class_accuracies[class_name] for class_name in class_labels.keys()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "vKPBSw9V0zcO",
      "metadata": {
        "id": "vKPBSw9V0zcO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class CAGA(nn.Module):\n",
        "    \"\"\"\n",
        "      Attributes:\n",
        "          heads: Number of attention heads in the multi-head attention mechanism.\n",
        "          dim: Dimensionality of Q, K, V.\n",
        "          scale: Scaling factor for the attention computation.\n",
        "          head_dim: The number of channels per attention head.\n",
        "          dilation: List of dilation values for dilated convolutions.\n",
        "          total_layer: Total number of layers used in the module.\n",
        "          get_begin: Initial convolutional layer for feature extraction.\n",
        "          get_qkv: List of convolutional layers to compute queries, keys, and values.\n",
        "          convert_to_headdim: Layer to combine and reshape the outputs of all dilated convolutions.\n",
        "          mix: Convolutional layers to refine the features.\n",
        "          proj: Final projection layer to map the concatenated features to the input shape.\n",
        "          norm: Batch normalization layer to normalize the output.\n",
        "      \"\"\"\n",
        "    def __init__(self,\n",
        "            in_channels,\n",
        "            activation,\n",
        "            heads = 3,\n",
        "            dim = 8,\n",
        "            expand_ratio = 4,\n",
        "            head_dim = 16,\n",
        "            dilation = (1,2),\n",
        "            random_seed = 82\n",
        "            ):\n",
        "\n",
        "        # Set global random seeds for reproducibility\n",
        "        self._set_global_seeds(random_seed)\n",
        "\n",
        "        super(CAGA, self).__init__()\n",
        "        self.heads = heads\n",
        "        self.dim = dim\n",
        "        scale = dim\n",
        "        self.scale = dim ** -0.5\n",
        "        self.head_dim = head_dim\n",
        "        self.dilation = dilation\n",
        "\n",
        "        self.total_layer = 4\n",
        "\n",
        "        # Reproducible layer initialization\n",
        "        self.get_begin = self._init_depthwise_separable_conv(\n",
        "            DepthWiseSeperableConvLayer(in_channels, self.heads * self.head_dim)\n",
        "        )\n",
        "\n",
        "        self.get_qkv = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                self._init_conv(nn.Conv2d(\n",
        "                    self.head_dim,\n",
        "                    self.head_dim,\n",
        "                    3,\n",
        "                    groups=self.head_dim,\n",
        "                    dilation=di\n",
        "                )),\n",
        "                self._init_conv(nn.Conv2d(self.head_dim, 3 * self.dim, 1, groups=1))\n",
        "            )\n",
        "            for di in dilation\n",
        "        ])\n",
        "\n",
        "        self.convert_to_headdim = self._init_conv(\n",
        "            nn.Conv2d(len(dilation) * self.dim, self.head_dim, 1)\n",
        "        )\n",
        "\n",
        "        self.mix = nn.Sequential(\n",
        "            self._init_conv(nn.Conv2d(\n",
        "                self.dim,\n",
        "                self.dim * 3,\n",
        "                1\n",
        "            )),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.proj = self._init_conv(\n",
        "            nn.Conv2d(self.heads * self.dim * len(self.dilation), in_channels, 1)\n",
        "        )\n",
        "\n",
        "        # Deterministic BatchNorm\n",
        "        self.norm = nn.BatchNorm2d(num_features=in_channels, affine=True)\n",
        "        nn.init.constant_(self.norm.weight, 1)\n",
        "        nn.init.constant_(self.norm.bias, 0)\n",
        "\n",
        "    def _set_global_seeds(self, seed):\n",
        "        \"\"\"Set seeds for reproducibility across libraries.\"\"\"\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        np.random.seed(seed)\n",
        "        random.seed(seed)\n",
        "\n",
        "    def _init_conv(self, conv_layer):\n",
        "        \"\"\"Initialize convolutional layer weights deterministically.\"\"\"\n",
        "        nn.init.xavier_uniform_(conv_layer.weight)\n",
        "        if conv_layer.bias is not None:\n",
        "            nn.init.constant_(conv_layer.bias, 0)\n",
        "        return conv_layer\n",
        "\n",
        "    def _init_depthwise_separable_conv(self, conv_layer):\n",
        "        \"\"\"Initialize depthwise separable convolution layers.\"\"\"\n",
        "        # Assuming DepthWiseSeperableConvLayer has similar structure to standard conv\n",
        "        for m in conv_layer.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "        return conv_layer\n",
        "        # self.norm = nn.LayerNorm([8, 256, 14, 14])\n",
        "\n",
        "\n",
        "\n",
        "    def attention(self,q,k,v , shape):\n",
        "\n",
        "        B, C, H, W = shape\n",
        "\n",
        "\n",
        "\n",
        "        q, k, v = q.float(), k.float(), v.float()\n",
        "\n",
        "\n",
        "        q = q * self.scale\n",
        "        att_map = q.transpose(-2, -1) @ k\n",
        "\n",
        "\n",
        "        att_map = att_map.softmax(dim=-1)\n",
        "\n",
        "\n",
        "        out = v @ att_map.transpose(-2, -1)\n",
        "\n",
        "        out = out.view(B , -1 , H , W)\n",
        "\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "    def forward(self,x):\n",
        "        B, C, H, W = x.shape\n",
        "\n",
        "\n",
        "\n",
        "            # print(op)\n",
        "\n",
        "        x_copy = x\n",
        "\n",
        "        all_heads  = self.get_begin(x)\n",
        "\n",
        "        multi_layer = all_heads.split([self.head_dim]*self.heads , dim=1)\n",
        "\n",
        "        all_heads_after_op = [[]]*self.heads\n",
        "\n",
        "\n",
        "\n",
        "        for j in range(self.heads):\n",
        "\n",
        "            for op in self.get_qkv:\n",
        "\n",
        "                all_heads_after_op[j].append(op(multi_layer[j]))\n",
        "\n",
        "\n",
        "        all_final = []\n",
        "\n",
        "\n",
        "        for i in range(self.heads):\n",
        "            out_all = []\n",
        "            for j in range(len(self.dilation ) ):\n",
        "\n",
        "\n",
        "\n",
        "                q , k , v = all_heads_after_op[i][j].split([self.dim, self.dim, self.dim], dim=1)\n",
        "                shape = q.shape\n",
        "                q, k, v = q.flatten(2), k.flatten(2), v.flatten(2)\n",
        "                out = self.attention(q , k , v , shape)\n",
        "\n",
        "\n",
        "\n",
        "                # print(out.shape)\n",
        "                shape_ahead = all_heads_after_op[i][j+1].shape[3]\n",
        "\n",
        "                temp = torchvision.transforms.functional.resize(out , (shape_ahead,shape_ahead))\n",
        "\n",
        "                out = F.interpolate(out, size=( H , W ), mode='bilinear')\n",
        "                out = out.view(B, self.dim, H, W)\n",
        "\n",
        "\n",
        "                if j+1 != len(self.dilation ):\n",
        "\n",
        "                    temp = self.mix(temp).clone()\n",
        "                    all_heads_after_op[i][j+1] = all_heads_after_op[i][j+1] + temp\n",
        "\n",
        "                out_all.append(out)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            out_all_one = torch.cat(out_all, dim=1)\n",
        "            all_final.append(out_all_one)\n",
        "            if i+1 != self.heads:\n",
        "                all_heads_after_op[i+1] += self.convert_to_headdim(out_all_one)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # we need to billinear intterpolate before append\n",
        "        all_concat = torch.cat(all_final, dim=1)\n",
        "\n",
        "\n",
        "        x_final = self.proj(all_concat) + x_copy # try oncat later\n",
        "\n",
        "        return self.norm (x_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "fef97e6c-20f5-47bf-8a91-6ec50aea4c48",
      "metadata": {
        "id": "fef97e6c-20f5-47bf-8a91-6ec50aea4c48"
      },
      "outputs": [],
      "source": [
        "class EarlyStopper:\n",
        "    def __init__(self, patience=1, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.max_validation_acc = float('-inf')\n",
        "        self.val_acc_1 = 0\n",
        "        self.perfect_val_count =6\n",
        "\n",
        "    def early_stop(self, validation_acc):\n",
        "\n",
        "\n",
        "        if validation_acc > self.max_validation_acc:\n",
        "            self.max_validation_acc = validation_acc\n",
        "            self.counter = 0\n",
        "        elif validation_acc <= (self.max_validation_acc - self.min_delta):\n",
        "            print(\"max_acc\" , self.max_validation_acc)\n",
        "\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return (True,self.counter)\n",
        "        return (False,self.counter)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "ZV8jE5VAKlNv",
      "metadata": {
        "id": "ZV8jE5VAKlNv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "\n",
        "\n",
        "def training(model_name , model_config_name, HYPERPARAMS,X_train, y_train, X_val, y_val, X_test, y_test,Module = 'CAGA' , pre_trained = True,run = 1):\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    accuracy_dict_train = {}\n",
        "    accuracy_dict_val = {}\n",
        "    loss_dict_train = {}\n",
        "    loss_dict_val = {}\n",
        "    accu = []\n",
        "\n",
        "    # Initialize metrics\n",
        "    accuracy_avg = 0\n",
        "    precision_avg = 0\n",
        "    recall_avg = 0\n",
        "    f1_avg = 0\n",
        "    model_name = model_name\n",
        "    # Create directories using Cola paths\n",
        "    csv_dir = f'/results/run_{run}'\n",
        "    os.makedirs(csv_dir, exist_ok=True)\n",
        "\n",
        "    main_csv_path = os.path.join(csv_dir, f'results_{timestamp}_{model_name}.csv')\n",
        "\n",
        "    # Initialize main results CSV\n",
        "    header = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1'] + \\\n",
        "         [f'{class_name} Accuracy' for class_name in class_labels.keys()] + \\\n",
        "         list(HYPERPARAMS.keys())\n",
        "\n",
        "    with open(main_csv_path, 'w', newline='') as csvfile:\n",
        "        csvwriter = csv.writer(csvfile)\n",
        "        csvwriter.writerow(header)\n",
        "\n",
        "    model_num = 0\n",
        "    print(f\"####################################\")\n",
        "\n",
        "    X_train_norm, X_val_norm, X_test_norm = norm(X_train, X_val, X_test)\n",
        "\n",
        "    epoch_number = 0\n",
        "    alpha = torch.tensor([0.81, 1.12]).to(device)\n",
        "\n",
        "\n",
        "    model = timm.create_model(model_config_name, pretrained= pre_trained) #for ablation turn pre-trained to False\n",
        "    if Module == 'CAGA':\n",
        "        replace_context_modules(model, CAGA, dilation = HYPERPARAMS['dilation']) # comment this for all other models apart for efficientViT-CAGA\n",
        "    change_classifier(model, model_config_name, dropout=HYPERPARAMS['dropout'], neurons1=HYPERPARAMS['neurons1'], neurons2=HYPERPARAMS['neurons2'], neurons3=HYPERPARAMS['neurons3'], neurons4=HYPERPARAMS['neurons4'], n_layers=HYPERPARAMS['n_layers'])\n",
        "\n",
        "    print(model)\n",
        "    model.to(device)\n",
        "    \n",
        "\n",
        "    training_loader = DataLoader(list(zip(torch.Tensor(X_train_norm).to(device), torch.Tensor(y_train).to(device))), batch_size=HYPERPARAMS['batch_size_train'], shuffle=True)\n",
        "    validation_loader = DataLoader(list(zip(torch.Tensor(X_val_norm).to(device), torch.Tensor(y_val).to(device))), batch_size=HYPERPARAMS['batch_size_val'], shuffle=True)\n",
        "    test_loader = DataLoader(list(zip(torch.Tensor(X_test_norm).to(device), torch.Tensor(y_test).to(device))), batch_size=HYPERPARAMS['batch_size_test'], shuffle=False)\n",
        "\n",
        "    loss_fn = torch.nn.BCELoss()\n",
        "    loss_fn1 = torch.nn.CrossEntropyLoss()\n",
        "    #loss_fn = FocalCELoss( alpha = alpha, gamma=2.0, num_classes=2)\n",
        "    w = 0\n",
        "    optimizer = torch.optim.AdamW(params=model.parameters(), lr=HYPERPARAMS['learning_rate'], weight_decay=HYPERPARAMS['weight_decay'])\n",
        "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=HYPERPARAMS['scheduler_gamma'])\n",
        "    early_stopper = EarlyStopper(patience=HYPERPARAMS['patience'], min_delta=HYPERPARAMS['min_delta'])\n",
        "\n",
        "    for epoch in range(HYPERPARAMS['EPOCH']):\n",
        "        print(f\"Learning rate: {optimizer.param_groups[0]['lr']}\")\n",
        "        print(f'EPOCH {epoch}:')\n",
        "\n",
        "        model.train(True)\n",
        "        avg_loss, train_accuracy, right, *class_accuracies_train = train_one_epoch(model, epoch_number, model_num, training_loader, loss_fn, loss_fn1, w, optimizer, loss_dict_train)\n",
        "\n",
        "        print(f\"Average loss: {avg_loss}\")\n",
        "\n",
        "        running_vloss = 0.0\n",
        "        model.eval()\n",
        "        vright_total = 0\n",
        "        total_val = 0\n",
        "\n",
        "        class_totals_val = {class_name: 0 for class_name in class_labels.keys()}\n",
        "        class_rights_val = {class_name: 0 for class_name in class_labels.keys()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, vdata in enumerate(validation_loader):\n",
        "                vinputs, vlabels = vdata\n",
        "                total_val += vinputs.shape[0]\n",
        "\n",
        "                voutputs = model(vinputs)\n",
        "                vloss = (1 - w) * loss_fn(voutputs, vlabels) + w * loss_fn1(voutputs, vlabels)\n",
        "\n",
        "                class_totals_batch = cal_total(vlabels)\n",
        "                vright, *class_rights_batch = acc_eval(voutputs, vlabels, classwise=True)\n",
        "\n",
        "                vright_total += vright\n",
        "\n",
        "                for j, class_name in enumerate(class_labels.keys()):\n",
        "                    class_totals_val[class_name] += class_totals_batch[j]\n",
        "                    class_rights_val[class_name] += class_rights_batch[j]\n",
        "\n",
        "                running_vloss += vloss\n",
        "\n",
        "        avg_vloss = running_vloss / (i + 1)\n",
        "        print(f\"Validation loss: {avg_vloss}\")\n",
        "\n",
        "        class_accuracies_val = {class_name: class_rights_val[class_name] / class_totals_val[class_name] if class_totals_val[class_name] > 0 else None for class_name in class_labels.keys()}\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        val_acc = vright_total / total_val\n",
        "\n",
        "        print(f\"Validation accuracy: {val_acc}\")\n",
        "        print(f'LOSS train {avg_loss} valid {avg_vloss}')\n",
        "        print(f'Right train {right} valid {vright_total}')\n",
        "        print(f'Accuracy train {train_accuracy} valid {val_acc}')\n",
        "\n",
        "\n",
        "        early = early_stopper.early_stop(val_acc)\n",
        "        print(\"Current early_stop count\", early[1])\n",
        "        if early[0]:\n",
        "            print('Early stopping triggered')\n",
        "            break\n",
        "\n",
        "    with torch.no_grad():\n",
        "        acc, precision, recall, f1, *class_accuracies_test = test(model, test_loader, model_num)\n",
        "        row = [model_name, acc, precision, recall, f1] + \\\n",
        "                    class_accuracies_test + \\\n",
        "                    list(HYPERPARAMS.values())\n",
        "\n",
        "        with open(main_csv_path, 'a', newline='') as csvfile:\n",
        "            csvwriter = csv.writer(csvfile)\n",
        "            csvwriter.writerow(row)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
