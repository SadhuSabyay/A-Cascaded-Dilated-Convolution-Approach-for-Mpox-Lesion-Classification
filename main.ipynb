{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9968217-93e7-431e-9f91-265b0d51fc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading hyperparameters from: MCSI/Scores and Hyperparams/coatnet/results_20241210_224219_coatnet_1_rw_224.sw_in1k.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'weight_decay': 0.01,\n",
       " 'neurons1': 1280,\n",
       " 'neurons2': 32,\n",
       " 'n_layers': 1,\n",
       " 'loss': 'FCE',\n",
       " 'lr': 6.134047274e-05}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def load_hyperparameters(model_name, dataset):\n",
    "    \"\"\"\n",
    "    Load hyperparameters for a specific model and dataset from CSV files in the directory structure:\n",
    "    <dataset>/Scores and Hyperparams/<model_name>/*.csv\n",
    "    \n",
    "    Parameters:\n",
    "    model_name (str): Name of the model (e.g., 'efficientvit_l1')\n",
    "    dataset (str): Name of the dataset (e.g., 'msld', 'msid', 'caap')\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary with required hyperparameters\n",
    "    \"\"\"\n",
    "    # Define the expected hyperparameters and their types\n",
    "    expected_params = {\n",
    "        'EPOCH': int,\n",
    "        'batch_size_train': int,\n",
    "        'batch_size_val': int,\n",
    "        'batch_size_test': int,\n",
    "        'learning_rate': float,\n",
    "        'weight_decay': float,\n",
    "        'patience': int,\n",
    "        'min_delta': float,\n",
    "        'scheduler_gamma': float,\n",
    "        'dropout': float,\n",
    "        'neurons1': int,\n",
    "        'neurons2': int,\n",
    "        'neurons3': int,\n",
    "        'neurons4': int,\n",
    "        'n_layers': int,\n",
    "        'dilation': ast.literal_eval,\n",
    "        'loss': str,\n",
    "        'lr': float,\n",
    "        \n",
    "    }\n",
    "    \n",
    "    # Construct the path to the model's directory\n",
    "    base_path = Path(dataset) / 'Scores and Hyperparams' / model_name\n",
    "    \n",
    "    # Check if directory exists\n",
    "    if not base_path.exists():\n",
    "        raise FileNotFoundError(f\"Directory not found: {base_path}\")\n",
    "    \n",
    "    # Find all CSV files in the directory\n",
    "    csv_files = list(base_path.glob('*.csv'))\n",
    "    \n",
    "    if not csv_files:\n",
    "        raise FileNotFoundError(f\"No CSV files found in {base_path}\")\n",
    "    \n",
    "    # Use the first CSV file found\n",
    "    csv_path = csv_files[0]\n",
    "    print(f\"Loading hyperparameters from: {csv_path}\")\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Initialize the hyperparameters dictionary\n",
    "    hyperparams = {}\n",
    "    \n",
    "    # Get the first row of data\n",
    "    row = df.iloc[0]\n",
    "    \n",
    "    # Extract parameters and convert to appropriate types\n",
    "    for param, param_type in expected_params.items():\n",
    "        if param in row:\n",
    "            try:\n",
    "                if param == 'dilation':\n",
    "                    hyperparams[param] = ast.literal_eval(str(row[param]))\n",
    "                else:\n",
    "                    hyperparams[param] = param_type(row[param])\n",
    "            except (ValueError, KeyError, SyntaxError) as e:\n",
    "                print(f\"Warning: Could not convert {param}. Error: {e}\")\n",
    "    \n",
    "    return hyperparams\n",
    "\n",
    "# Example usage:\n",
    "load_hyperparameters('coatnet', 'MCSI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb001ad7-315b-4775-ae32-411f3abbb509",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EfficientViT-CAGA: Main Configuration File\n",
    "This file contains the primary configuration and execution logic for the EfficientViT-CAGA model,\n",
    "including hyperparameter settings, model configurations, and training execution across different datasets.\n",
    "\n",
    "Authors: Ayush Deshmukh\n",
    "Date: 27th Dec\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "from typing import Dict, Tuple, Union\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Hyperparameter configurations for MSLD and MSID datasets\n",
    "HYPERPARAMS_MSLD_MSID = {\n",
    "    # Training parameters\n",
    "    'EPOCH': 30,\n",
    "    'batch_size_train': 16,\n",
    "    'batch_size_val': 16,\n",
    "    'batch_size_test': 8,\n",
    "    'learning_rate': 0.0000614447274,\n",
    "    'weight_decay': 0.01,\n",
    "    'patience': 7,\n",
    "    'min_delta': 0,\n",
    "    'scheduler_gamma': 0.95,\n",
    "    \n",
    "    # Model architecture\n",
    "    'dropout': 0.111975,\n",
    "    'neurons1': 1024,\n",
    "    'neurons2': 2048,\n",
    "    'neurons3': 512,\n",
    "    'neurons4': 512,\n",
    "    'n_layers': 2,\n",
    "    'dilation': (1, 2),  # Dilations for CAGA module\n",
    "}\n",
    "\n",
    "# Hyperparameter configurations for MCSI dataset\n",
    "HYPERPARAMS_MCSI = {\n",
    "    # Training parameters\n",
    "    'lr': 0.0000648047274,\n",
    "    'weight_decay': 0.01,\n",
    "    \n",
    "    # Model architecture\n",
    "    'neurons1': 1024,\n",
    "    'neurons2': 2048,\n",
    "    'n_layers': 2,\n",
    "    'dilation': (1, 2),  # Dilations for CAGA module\n",
    "    'loss': 'FCE',  # Options: 'FocalCE', 'CE', 'BCE'\n",
    "}\n",
    "\n",
    "# Supported model configurations\n",
    "SUPPORTED_MODELS = [\n",
    "    'resnet101.a1_in1k',\n",
    "    'deit3_medium_patch16_224',\n",
    "    'coatnet_1_rw_224.sw_in1k',\n",
    "    'mobilenetv3_large_100.ra_in1k',\n",
    "    'vit_base_patch16_224',\n",
    "    'efficientvit_l1.r224_in1k'  # Primary model for EfficientViT-CAGA results\n",
    "]\n",
    "\n",
    "# Module configurations for ablation study\n",
    "MODULE_VARIANTS = {\n",
    "    'CAGA': 'Complete CAGA module with cascading',\n",
    "    'CAA': 'Only CAA module without CAGA',\n",
    "    'CAGA_nocascading_in_CAA': 'CAGA module without cascading in CAA',\n",
    "\n",
    "}\n",
    "\n",
    "MODEL_NAMES = [\n",
    "    'coatnet', 'DEIT3_medium', 'EfficientViT', 'EfficientViT-CAGA', 'mobilenet_large', 'resnet101', 'ViTBase'\n",
    "    \n",
    "]\n",
    "\n",
    "def main(\n",
    "    dataset: str,\n",
    "    model_name: str,\n",
    "    model_config_name: str,\n",
    "    module: str = 'CAGA',\n",
    "    pre_trained: bool = True,\n",
    "    run: int = 1\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Main execution function for training and evaluation across different datasets.\n",
    "    \n",
    "    Args:\n",
    "        dataset: Dataset name ('MCSI', 'MSLD', or 'MSID')\n",
    "        model_name: Base model architecture name\n",
    "        model_config_name: Specific model configuration name\n",
    "        hyperparams: Dictionary containing hyperparameters\n",
    "        module: Module variant for ablation study ('CAGA', 'CAA', or 'CAGA_nocascading_in_CAA')\n",
    "        pre_trained: Whether to use pre-trained weights\n",
    "        run: Run number for experiment tracking\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If invalid dataset is specified\n",
    "    \"\"\"\n",
    "    if dataset not in ['MCSI', 'MSLD', 'MSID']:\n",
    "        raise ValueError(f\"Invalid dataset: {dataset}. Must be one of: MCSI, MSLD, MSID\")\n",
    "    \n",
    "   \n",
    "    logger.info(f\"Starting training for {dataset} dataset using {model_name} with {module} module\")\n",
    "    \n",
    "    if dataset == 'MCSI':\n",
    "        hyperparams = load_hyperparameters(model_name, dataset)\n",
    "        %run MCSI_Implementation.ipynb\n",
    "        training(model_name, model_config_name, hyperparams, module, pre_trained, run=run)\n",
    "    \n",
    "    elif dataset == 'MSLD':\n",
    "        hyperparams = load_hyperparameters(model_name, dataset)\n",
    "        %run MSLD_Implementation.ipynb\n",
    "        training(model_name, model_config_name, hyperparams, X_train, y_train, \n",
    "                X_val, y_val, X_test, y_test, module, pre_trained, run=run)\n",
    "    \n",
    "    elif dataset == 'MSID':\n",
    "        hyperparams = load_hyperparameters(model_name, dataset)\n",
    "        %run MSID_implementation.ipynb\n",
    "        training(model_name, model_config_name, hyperparams, X_train, y_train,\n",
    "                X_test, y_test, module, pre_trained, run=run)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage for EfficientViT-CAGA with ablation study\n",
    "    main(\n",
    "        dataset='MSID',\n",
    "        model_name='EfficientViT-CAGA',\n",
    "        model_config_name='efficientvit_l1.r224_in1k',\n",
    "        module= 'CAGA', #use None for all models other than  EfficientViT-CAGA\n",
    "        pre_trained=True,\n",
    "        run=1\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
